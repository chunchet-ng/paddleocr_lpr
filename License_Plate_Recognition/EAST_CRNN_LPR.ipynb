{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"3i45jwHyzlSC"},"source":["## Mount GDrive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3024,"status":"ok","timestamp":1683728352635,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"CSrmdTXqvn9w","outputId":"43cff59f-56f2-4f17-a483-894cbd767f46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683728352636,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"6tLWyxVEyo1T","outputId":"45537d6e-402f-4655-e680-5d07d1ffa765"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive\n","/content/drive/My Drive/CCPD2019\n","CCPD2019.zip  train_crop     train.txt\tval_crop     val.txt\n","train\t      train_rec.txt  val\tval_rec.txt\n"]}],"source":["%cd \"/content/drive/My Drive\"\n","%cd \"CCPD2019\"\n","!ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WGcFIpNrzw28"},"source":["## Install PPOCR"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":35418,"status":"ok","timestamp":1683728388049,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"zsD-t3CsK4zs","outputId":"963c687f-f034-4cba-d4c8-60090341aed5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition\n","fatal: destination path 'PaddleOCR' already exists and is not an empty directory.\n","/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.3)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.0)\n","Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.3.0.post4)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: visualdl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.2)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.0.0)\n","Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.6.0.66)\n","Requirement already satisfied: opencv-contrib-python==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.6.0.66)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.29.34)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.9.2)\n","Requirement already satisfied: premailer in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.10.0)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.0.10)\n","Requirement already satisfied: attrdict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.0.1)\n","Requirement already satisfied: Polygon3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.0.9.1)\n","Requirement already satisfied: lanms-neo==1.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (1.0.2)\n","Requirement already satisfied: PyMuPDF<1.21.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.20.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.10.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (8.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (23.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (1.16.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: bce-python-sdk in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (0.8.83)\n","Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.2.4)\n","Requirement already satisfied: Flask-Babel>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.1.0)\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.20.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.5.3)\n","Requirement already satisfied: x2paddle>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: paddle2onnx>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.0.6)\n","Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (4.0)\n","Requirement already satisfied: gradio==3.11.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.11.0)\n","Requirement already satisfied: tritonclient[all] in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.33.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (5.9.5)\n","Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.14.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.8.4)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.95.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.3.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2023.4.0)\n","Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.12.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.24.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.2.0)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.8.12)\n","Requirement already satisfied: paramiko in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.1.0)\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.17)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.10.7)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.0.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.22.0)\n","Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (11.0.3)\n","Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (1.2.0)\n","Requirement already satisfied: cssutils in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (2.6.0)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (5.3.0)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->-r requirements.txt (line 15)) (1.1.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.3.0)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (8.1.3)\n","Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2.12.1)\n","Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2022.7.1)\n","Collecting protobuf>=3.20.0 (from visualdl->-r requirements.txt (line 8))\n","  Downloading protobuf-4.23.0-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.6.0->visualdl->-r requirements.txt (line 8)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.11.1)\n","Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->-r requirements.txt (line 8)) (0.18.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.4)\n","Requirement already satisfied: python-rapidjson>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.10)\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.54.0)\n","Requirement already satisfied: geventhttpclient<=2.0.2,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.1)\n","Requirement already satisfied: gevent>=0.13 in /usr/local/lib/python3.10/dist-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (22.10.2)\n","Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.1.2)\n","Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.26.1)\n","Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.15.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.1.2)\n","Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.3.5)\n","Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (4.0.1)\n","Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (40.0.2)\n","Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.5.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.15.1)\n","Requirement already satisfied: zope.event in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (4.6)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (67.7.2)\n","Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.6.2)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.0.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.21)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.0\n","    Uninstalling protobuf-3.20.0:\n","      Successfully uninstalled protobuf-3.20.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","paddlepaddle 2.4.2 requires protobuf<=3.20.0,>=3.1.0, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.10/dist-packages (2.4.2)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (2.27.1)\n","Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.22.4)\n","Collecting protobuf<=3.20.0,>=3.1.0 (from paddlepaddle)\n","  Using cached protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (8.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.16.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n","Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.8.1)\n","Requirement already satisfied: paddle-bfloat==0.1.7 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.1.7)\n","Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","onnx 1.14.0 requires protobuf>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n","tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"}],"source":["%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/\"\n","!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n","%cd ./PaddleOCR\n","!pip install -r requirements.txt\n","!pip install paddlepaddle"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683728388050,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"dck-MuVWBH3F"},"outputs":[],"source":["# Uncomment them to download checkpoints for east and crnn.\n","\n","# %cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\"\n","# !rm -rf *.tar*\n","# !wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n","# !tar xvf det_mv3_east_v2.0_train.tar\n","\n","# %cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\"v\n","# !rm -rf *.tar*\n","# !wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n","# !tar xvf rec_mv3_none_bilstm_ctc_v2.0_train.tar"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Define Commonly Used Functions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from paddle import fluid\n","\n","\n","def reset_dygraph():\n","    fluid.dygraph.disable_dygraph()\n","    fluid.dygraph.enable_dygraph()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qkVCWdZvPxq9"},"source":["## Text Detection Using Pre-trained EAST"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800,"status":"ok","timestamp":1683728388847,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"_lNzSFjrRwaR","outputId":"89d5e860-98b1-4db4-8b09-aa5389114f61"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n","applications  doc\t   paddleocr.py  README_ch.md\t   StyleText\n","benchmark     __init__.py  ppocr\t README.md\t   test_tipc\n","configs       LICENSE\t   PPOCRLabel\t requirements.txt  tools\n","deploy\t      MANIFEST.in  ppstructure\t setup.py\t   train.sh\n"]}],"source":["%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39644,"status":"ok","timestamp":1683728428486,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"nRhS2KSZcheZ","outputId":"d599c78b-2180-45ee-a71d-7404de6aaf6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:19:51] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:35<00:00,  1.79s/it]\n"]}],"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import yaml\n","import argparse\n","import numpy as np\n","from tqdm import tqdm\n","\n","import paddle\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def draw_det_res(dt_boxes, img, img_name, save_path):\n","    if len(dt_boxes) > 0:\n","        src_im = img\n","        for box in dt_boxes:\n","            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        save_path = os.path.join(save_path, os.path.basename(img_name))\n","        cv2.imwrite(save_path, src_im)\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_det(config_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","\n","    # build model\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'])\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name == 'KeepKeys':\n","            op[op_name]['keep_keys'] = ['image', 'shape']\n","        transforms.append(op)\n","\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_output\"\n","vis_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_output/vis\"\n","det_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","if not os.path.exists(vis_path):\n","  os.makedirs(vis_path)\n","\n","# Paddle OCR Configs\n","detConfig, detModel, detOPS, detPost = init_det(det_yml)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_arr = []\n","\n","with open(os.path.join(out_path, 'east_output.txt'), mode='w') as out_f:\n","  for idx, img_name in enumerate(tqdm(images)):\n","      im_id = img_name.split('/')[-1].replace('.jpg', '')\n","      \n","      bbox_outputs = []\n","      with open(img_name, 'rb') as f:\n","          img = f.read()\n","          data = {'image': img}\n","\n","      batch = transform(data, detOPS)\n","      images = np.expand_dims(batch[0], axis=0)\n","      shape_list = np.expand_dims(batch[1], axis=0)\n","      images = paddle.to_tensor(images)\n","\n","      # forward & post process\n","      preds = detModel(images)\n","      det_res = detPost(preds, shape_list)\n","\n","      # parser boxes if post_result is dict\n","      if isinstance(det_res, dict):\n","          for k in det_res.keys():\n","              boxes = det_res[k][0]['points']\n","      else:\n","          boxes = det_res[0]['points']\n","\n","      dt_boxes_json = []\n","      # write predictions to images\n","      draw_det_res(boxes, cv2.imread(img_name), img_name, vis_path)\n","      \n","      boxes_len = len(boxes)\n","      if boxes_len == 0:\n","          print(f'No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}')\n","          continue\n","      else:\n","          for box in boxes:\n","            box_list = box.tolist()\n","            \n","            current_res_dict = {\n","                \"points\": box_list\n","            }\n","            bbox_outputs.append(current_res_dict)\n","\n","      out_f.write(f'{os.path.basename(img_name)}\\t{json.dumps(bbox_outputs)}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2tV2TdaUli2F"},"source":["## Text Detection Evaluation"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683728428486,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"lpDrLo97nYaE","outputId":"4a7525d3-c271-48ca-fbcc-1ed2defa3cda"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.06, Recall: 0.25, HMean: 0.1\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","from det_eval import evaluation\n","from collections import defaultdict\n","\n","eval_config = {\n","    'IOU_CONSTRAINT' : 0.5,\n","    'AREA_PRECISION_CONSTRAINT' : 0.5,\n","    'WORD_SPOTTING' : False,\n","    'PER_SAMPLE_RESULTS': True #Generate per sample results and produce data for visualization,\n","}\n","\n","# Prepare GT\n","gt_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/CCPD2019/val.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","      gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","# Prepare Det\n","det_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_output/east_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","\n","      width = xmax - xmin\n","      height = ymax - ymin\n","\n","      det_dict[img_id].append([xmin, ymin, xmax, ymax])\n","\n","resDict = evaluation(gt_dict, det_dict, eval_config)\n","precision, recall, hmean = resDict['method']['precision'], resDict['method']['recall'], resDict['method']['hmean']\n","print('---Overall Metric---')\n","print(f'Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean: {round(hmean, 2)}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gwzLm-WC0pMi"},"source":["## Text Recognition Using Pre-trained CRNN"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1985,"status":"ok","timestamp":1683728430460,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"fBIKUCHn0uOe","outputId":"0bc749d8-a950-456a-ad61-4cf5aa96fb4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:20:28] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n","[2023/05/10 14:20:28] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n","[2023/05/10 14:20:28] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:01<00:00, 16.10it/s]\n"]}],"source":["import os\n","import glob\n","import sys\n","import cv2\n","import json\n","import yaml\n","import shutil\n","import argparse\n","import numpy as np\n","from tqdm import tqdm\n","\n","from collections import defaultdict\n","\n","import paddle\n","\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","from ppocr.utils.utility import get_image_file_list\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_rec(config_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'],\n","                                            global_config)\n","\n","    # build model\n","    if hasattr(post_process_class, 'character'):\n","        char_num = len(getattr(post_process_class, 'character'))\n","        if config['Architecture'][\"algorithm\"] in [\"Distillation\",\n","                                                   ]:  # distillation model\n","            for key in config['Architecture'][\"Models\"]:\n","                if config['Architecture']['Models'][key]['Head'][\n","                        'name'] == 'MultiHead':  # for multi head\n","                    out_channels_list = {}\n","                    if config['PostProcess'][\n","                            'name'] == 'DistillationSARLabelDecode':\n","                        char_num = char_num - 2\n","                    out_channels_list['CTCLabelDecode'] = char_num\n","                    out_channels_list['SARLabelDecode'] = char_num + 2\n","                    config['Architecture']['Models'][key]['Head'][\n","                        'out_channels_list'] = out_channels_list\n","                else:\n","                    config['Architecture'][\"Models\"][key][\"Head\"][\n","                        'out_channels'] = char_num\n","        elif config['Architecture']['Head'][\n","                'name'] == 'MultiHead':  # for multi head loss\n","            out_channels_list = {}\n","            if config['PostProcess']['name'] == 'SARLabelDecode':\n","                char_num = char_num - 2\n","            out_channels_list['CTCLabelDecode'] = char_num\n","            out_channels_list['SARLabelDecode'] = char_num + 2\n","            config['Architecture']['Head'][\n","                'out_channels_list'] = out_channels_list\n","        else:  # base rec model\n","            config['Architecture'][\"Head\"]['out_channels'] = char_num\n","\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name in ['RecResizeImg']:\n","            op[op_name]['infer_mode'] = True\n","        elif op_name == 'KeepKeys':\n","            if config['Architecture']['algorithm'] == \"SRN\":\n","                op[op_name]['keep_keys'] = [\n","                    'image', 'encoder_word_pos', 'gsrm_word_pos',\n","                    'gsrm_slf_attn_bias1', 'gsrm_slf_attn_bias2'\n","                ]\n","            elif config['Architecture']['algorithm'] == \"SAR\":\n","                op[op_name]['keep_keys'] = ['image', 'valid_ratio']\n","            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n","                op[op_name][\n","                    'keep_keys'] = ['image', 'valid_ratio', 'word_positons']\n","            else:\n","                op[op_name]['keep_keys'] = ['image']\n","        transforms.append(op)\n","    global_config['infer_mode'] = True\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/crnn_output\"\n","reg_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","# Paddle OCR Configs\n","recConfig, recModel, recOPS, recPost = init_rec(reg_yml)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_arr = []\n","\n","with open(os.path.join(out_path, 'crnn_output.txt'), mode='w') as out_f:\n","    for idx, img_name in enumerate(tqdm(images)):\n","        im_id = img_name.split('/')[-1].replace('.jpg', '')\n","\n","        with open(img_name, 'rb') as f:\n","            img = f.read()\n","            data = {'image': img}\n","        batch = transform(data, recOPS)\n","        images = np.expand_dims(batch[0], axis=0)\n","        images = paddle.to_tensor(images)\n","        preds = recModel(images)\n","        \n","        rec_res = recPost(preds)\n","        formatted_res = rec_res[0][0].replace(' ', '')\n","        out_f.write(f'{os.path.basename(img_name)}\\t{formatted_res}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AzXgaEma79ob"},"source":["## Text Recognition Evaluation"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8740,"status":"ok","timestamp":1683728439198,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"IY7KjqJe707p","outputId":"dfa59040-10c9-41cf-e8e4-b22ab61db7d7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein) (3.0.0)\n"]}],"source":["!pip install levenshtein"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683728439198,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"mRYFc5Bi5cMP","outputId":"791cb25c-99f5-46bc-c94e-25e80f5cdf8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Correctly Recognized Words: 0.0\n","Total Correctly Recognized Words (Case Insensitive): 0.0\n","Total Edit Distance: 353\n","Total Edit Distance (Case Insensitive): 349\n"]}],"source":["# Let's evaluate the HMean for them\n","from rec_eval import total_accuracy, total_edit_distance\n","\n","# Prepare GT\n","gt_dict = {}\n","with open(\"/content/drive/My Drive/CCPD2019/val_rec.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    gt_dict[img_id] = values[1]\n","\n","# Prepare Det\n","det_dict = {}\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/crnn_output/crnn_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    det_dict[img_id] = values[1]\n","\n","gt = []\n","pred = []\n","\n","for key, val in gt_dict.items():\n","  if key in det_dict.keys():\n","    gt.append(val)\n","    pred.append(det_dict[key])\n","\n","total_acc, total_acc_ci = total_accuracy(gt, pred)\n","total_edit, total_edit_ci = total_edit_distance(gt, pred)\n","\n","print(f'Total Correctly Recognized Words: {total_acc}')\n","print(f'Total Correctly Recognized Words (Case Insensitive): {total_acc_ci}')\n","print(f'Total Edit Distance: {total_edit}')\n","print(f'Total Edit Distance (Case Insensitive): {total_edit_ci}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8xtpP0rz-_CO"},"source":["## Text Spotting Using Pre-trained EAST + CRNN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39894,"status":"ok","timestamp":1683728479080,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"DEkm-Rkh--DK","outputId":"e57833f3-6a00-41cb-dd42-c1e7afd0e5bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:20:39] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n","[2023/05/10 14:20:39] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n","[2023/05/10 14:20:39] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n","[2023/05/10 14:20:39] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:39<00:00,  1.96s/it]\n"]}],"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import yaml\n","import shutil\n","import numpy as np\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","import paddle\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","from ppocr.utils.utility import get_image_file_list\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def draw_det_res(dt_boxes, img, img_name, save_path):\n","    if len(dt_boxes) > 0:\n","        src_im = img\n","        for box in dt_boxes:\n","            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        save_path = os.path.join(save_path, os.path.basename(img_name))\n","        cv2.imwrite(save_path, src_im)\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_det(config_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","\n","    # build model\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'])\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name == 'KeepKeys':\n","            op[op_name]['keep_keys'] = ['image', 'shape']\n","        transforms.append(op)\n","\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","def init_rec(config_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'],\n","                                            global_config)\n","\n","    # build model\n","    if hasattr(post_process_class, 'character'):\n","        char_num = len(getattr(post_process_class, 'character'))\n","        if config['Architecture'][\"algorithm\"] in [\"Distillation\",\n","                                                   ]:  # distillation model\n","            for key in config['Architecture'][\"Models\"]:\n","                if config['Architecture']['Models'][key]['Head'][\n","                        'name'] == 'MultiHead':  # for multi head\n","                    out_channels_list = {}\n","                    if config['PostProcess'][\n","                            'name'] == 'DistillationSARLabelDecode':\n","                        char_num = char_num - 2\n","                    out_channels_list['CTCLabelDecode'] = char_num\n","                    out_channels_list['SARLabelDecode'] = char_num + 2\n","                    config['Architecture']['Models'][key]['Head'][\n","                        'out_channels_list'] = out_channels_list\n","                else:\n","                    config['Architecture'][\"Models\"][key][\"Head\"][\n","                        'out_channels'] = char_num\n","        elif config['Architecture']['Head'][\n","                'name'] == 'MultiHead':  # for multi head loss\n","            out_channels_list = {}\n","            if config['PostProcess']['name'] == 'SARLabelDecode':\n","                char_num = char_num - 2\n","            out_channels_list['CTCLabelDecode'] = char_num\n","            out_channels_list['SARLabelDecode'] = char_num + 2\n","            config['Architecture']['Head'][\n","                'out_channels_list'] = out_channels_list\n","        else:  # base rec model\n","            config['Architecture'][\"Head\"]['out_channels'] = char_num\n","\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name in ['RecResizeImg']:\n","            op[op_name]['infer_mode'] = True\n","        elif op_name == 'KeepKeys':\n","            if config['Architecture']['algorithm'] == \"SRN\":\n","                op[op_name]['keep_keys'] = [\n","                    'image', 'encoder_word_pos', 'gsrm_word_pos',\n","                    'gsrm_slf_attn_bias1', 'gsrm_slf_attn_bias2'\n","                ]\n","            elif config['Architecture']['algorithm'] == \"SAR\":\n","                op[op_name]['keep_keys'] = ['image', 'valid_ratio']\n","            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n","                op[op_name][\n","                    'keep_keys'] = ['image', 'valid_ratio', 'word_positons']\n","            else:\n","                op[op_name]['keep_keys'] = ['image']\n","        transforms.append(op)\n","    global_config['infer_mode'] = True\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_crnn_output\"\n","det_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n","reg_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n","tmp_folder_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_crnn_output/tmp\"\n","\n","if os.path.isdir(tmp_folder_path):\n","    shutil.rmtree(tmp_folder_path)\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","# Paddle OCR Configs\n","detConfig, detModel, detOPS, detPost = init_det(det_yml)\n","recConfig, recModel, recOPS, recPost = init_rec(reg_yml)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_dict = defaultdict(list)\n","\n","with open(os.path.join(out_path, 'east_crnn_output.txt'), mode='w') as out_f:\n","    for idx, img_name in enumerate(tqdm(images)):\n","        img_id = os.path.basename(img_name)\n","        \n","        # -------------------------------- STAGE I DETECTION ------------------------------\n","        with open(img_name, 'rb') as f:\n","            img = f.read()\n","            data = {'image': img}\n","\n","        batch = transform(data, detOPS)\n","        images = np.expand_dims(batch[0], axis=0)\n","        shape_list = np.expand_dims(batch[1], axis=0)\n","        images = paddle.to_tensor(images)\n","\n","        # forward & post process\n","        preds = detModel(images)\n","        det_res = detPost(preds, shape_list)\n","\n","        # parser boxes if post_result is dict\n","        if isinstance(det_res, dict):\n","            for k in det_res.keys():\n","                boxes = det_res[k][0]['points']\n","        else:\n","            boxes = det_res[0]['points']\n","        \n","        # Crop to patches\n","        ori_img = cv2.imread(img_name)\n","        h, w, c = ori_img.shape\n","        if not os.path.exists(tmp_folder_path):\n","            os.mkdir(tmp_folder_path)\n","\n","        for i, box in enumerate(boxes):\n","            pt = box.tolist()\n","            try:\n","                xs = [x[0] for x in pt]\n","                xs = np.clip(np.array(xs), a_min=0, a_max=w).tolist()\n","                ys = [x[1] for x in pt]\n","                ys = np.clip(np.array(ys), a_min=0, a_max=h).tolist()\n","                minx = min(xs)\n","                miny = min(ys)\n","                maxx = max(xs)\n","                maxy = max(ys)\n","                \n","                if (maxx - minx) <= 0 or (maxy - miny) <= 0:\n","                    print(f'BBOX error occured when cropping image {os.path.basename(img_name)} of {i}-th box')\n","                    print(f'Processed BBOX {minx} {miny} {maxx} {maxy}')\n","                    print(f'Ori BBOX {pt}')\n","                    continue\n","                \n","                crop = ori_img[miny:maxy, minx:maxx]\n","                tmp_img_name = os.path.join('{}/{}_{}.jpg'.format(tmp_folder_path, img_name.split('/')[-1].split('.')[0], str(i)))\n","                cv2.imwrite(tmp_img_name, crop)\n","            except Exception as e:\n","                print(f'Error {e} occured when cropping image {os.path.basename(img_name)} of {i}-th box')\n","                continue\n","        \n","        boxes_len = len(boxes)\n","        tmp_folder_len = len(os.listdir(tmp_folder_path))\n","        if boxes_len == 0 or tmp_folder_len == 0:\n","            print(f'No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}, tmp_len: {tmp_folder_len}')\n","            shutil.rmtree(tmp_folder_path)\n","            continue\n","        \n","        if boxes_len != tmp_folder_len:\n","            print(f'mismatch bbox_len {boxes_len} and tmp_len {tmp_folder_len} for image {os.path.basename(img_name)}')\n","            shutil.rmtree(tmp_folder_path)\n","            continue\n","\n","        # ------------------------- Stage II Recognition ------------------------------\n","        for file in get_image_file_list(tmp_folder_path):\n","            with open(file, 'rb') as f:\n","                img = f.read()\n","                data = {'image': img}\n","            batch = transform(data, recOPS)\n","            images = np.expand_dims(batch[0], axis=0)\n","            images = paddle.to_tensor(images)\n","            preds = recModel(images)\n","                \n","            rec_res = recPost(preds)\n","            formatted_res = rec_res[0][0].replace(' ', '')\n","\n","            b_id = int(file.split('_')[-1].replace('.jpg', ''))\n","            crt_box = boxes[b_id]\n","\n","            output_dict[img_id].append({\n","                'points': crt_box.tolist(),\n","                'transcription': formatted_res,\n","            })\n","\n","        shutil.rmtree(tmp_folder_path)\n","            \n","        out_f.write(f'{img_id}\\t{json.dumps(output_dict[img_id])}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"T4xQ7K2t9z9I"},"source":["## Text Spotting Evaluation"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683729342275,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"FUrvo2rT915O","outputId":"cc3f7a8c-3d56-482f-c99f-28d2ea3224e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.0, Recall: 0.0, HMean: 0\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","from det_eval import evaluation\n","from collections import defaultdict\n","\n","eval_config = {\n","    'IOU_CONSTRAINT' : 0.5,\n","    'AREA_PRECISION_CONSTRAINT' : 0.5,\n","    'WORD_SPOTTING' : True,\n","    'PER_SAMPLE_RESULTS': True #Generate per sample results and produce data for visualization,\n","}\n","\n","# Prepare GT\n","gt_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/CCPD2019/val.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","      gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","# Prepare Det\n","det_dict = defaultdict(list)\n","rec_dict = {}\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/pretrained_results/east_crnn_output/east_crnn_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","\n","      width = xmax - xmin\n","      height = ymax - ymin\n","\n","      det_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","resDict = evaluation(gt_dict, det_dict, eval_config)\n","precision, recall, hmean = resDict['method']['precision'], resDict['method']['recall'], resDict['method']['hmean']\n","print('---Overall Metric---')\n","print(f'Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean: {round(hmean, 2)}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YK9u3dJ3FmKL"},"source":["## Fine-tuning EAST\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683728479870,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"7r65AU7aFp-B"},"outputs":[],"source":["# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n","# Please set Global.use_gpu=True if you are running on a machine with GPU\n","# Fine-tuning for 100 epochs took 4 mins 29 secs on V100\n","\n","# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\" \\\n","# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\" Global.use_gpu=False"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xUlpKV9-y-lM"},"source":["## Fine-tuning CRNN\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683728479871,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"AUqMuLg8I17_"},"outputs":[],"source":["# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n","# Please set Global.use_gpu=True if you are running on a machine with GPU\n","# Fine-tuning for 200 epochs took 5 mins 47 secs on V100\n","\n","# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\" \\\n","# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\" Global.use_gpu=False"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2jhnx3NmzDwX"},"source":["## Evaluate Fine-tuned EAST\n"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":403,"status":"ok","timestamp":1683728983962,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"y_dxujK16_sZ"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28986,"status":"ok","timestamp":1683729013944,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"ezu45JVlzLp6","outputId":"1d1c1ad5-db5e-42a4-e2f0-e3b24b6716e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:29:47] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n"]}],"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import yaml\n","import argparse\n","import numpy as np\n","from tqdm import tqdm\n","\n","import paddle\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def draw_det_res(dt_boxes, img, img_name, save_path):\n","    if len(dt_boxes) > 0:\n","        src_im = img\n","        for box in dt_boxes:\n","            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        save_path = os.path.join(save_path, os.path.basename(img_name))\n","        cv2.imwrite(save_path, src_im)\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_det(config_path, ft_model_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","    global_config['pretrained_model'] = ft_model_path\n","\n","    # build model\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'])\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name == 'KeepKeys':\n","            op[op_name]['keep_keys'] = ['image', 'shape']\n","        transforms.append(op)\n","\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_output\"\n","vis_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_output/vis\"\n","det_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n","ft_model_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","if not os.path.exists(vis_path):\n","  os.makedirs(vis_path)\n","\n","# Paddle OCR Configs\n","detConfig, detModel, detOPS, detPost = init_det(det_yml, ft_model_path)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_arr = []\n","\n","with open(os.path.join(out_path, 'east_output.txt'), mode='w') as out_f:\n","  for idx, img_name in enumerate(tqdm(images)):\n","      im_id = img_name.split('/')[-1].replace('.jpg', '')\n","      \n","      bbox_outputs = []\n","      with open(img_name, 'rb') as f:\n","          img = f.read()\n","          data = {'image': img}\n","\n","      batch = transform(data, detOPS)\n","      images = np.expand_dims(batch[0], axis=0)\n","      shape_list = np.expand_dims(batch[1], axis=0)\n","      images = paddle.to_tensor(images)\n","\n","      # forward & post process\n","      preds = detModel(images)\n","      det_res = detPost(preds, shape_list)\n","\n","      # parser boxes if post_result is dict\n","      if isinstance(det_res, dict):\n","          for k in det_res.keys():\n","              boxes = det_res[k][0]['points']\n","      else:\n","          boxes = det_res[0]['points']\n","\n","      dt_boxes_json = []\n","      # write predictions to images\n","      draw_det_res(boxes, cv2.imread(img_name), img_name, vis_path)\n","      \n","      boxes_len = len(boxes)\n","      if boxes_len == 0:\n","          print(f'No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}')\n","          continue\n","      else:\n","          for box in boxes:\n","            box_list = box.tolist()\n","            \n","            current_res_dict = {\n","                \"points\": box_list\n","            }\n","            bbox_outputs.append(current_res_dict)\n","\n","      out_f.write(f'{os.path.basename(img_name)}\\t{json.dumps(bbox_outputs)}\\n')"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":462,"status":"ok","timestamp":1683729025372,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"lXH2SiLu2Dq7","outputId":"78ad0009-578d-414b-e748-e61e64f66f6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.91, Recall: 1.0, HMean: 0.95\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","from det_eval import evaluation\n","from collections import defaultdict\n","\n","eval_config = {\n","    'IOU_CONSTRAINT' : 0.5,\n","    'AREA_PRECISION_CONSTRAINT' : 0.5,\n","    'WORD_SPOTTING' : False,\n","    'PER_SAMPLE_RESULTS': True #Generate per sample results and produce data for visualization,\n","}\n","\n","# Prepare GT\n","gt_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/CCPD2019/val.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","      gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","# Prepare Det\n","det_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_output/east_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","\n","      width = xmax - xmin\n","      height = ymax - ymin\n","\n","      det_dict[img_id].append([xmin, ymin, xmax, ymax])\n","\n","resDict = evaluation(gt_dict, det_dict, eval_config)\n","precision, recall, hmean = resDict['method']['precision'], resDict['method']['recall'], resDict['method']['hmean']\n","print('---Overall Metric---')\n","print(f'Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean: {round(hmean, 2)}\\n')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-zVcdOzHzHI-"},"source":["## Evaluate Fine-tuned CRNN\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2100,"status":"ok","timestamp":1683728513027,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"KFFf-JGQzIbk","outputId":"3bce62e0-11bc-49a8-d238-166bd9dde0f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:21:52] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:00<00:00, 33.35it/s]\n"]}],"source":["import os\n","import glob\n","import sys\n","import cv2\n","import json\n","import yaml\n","import shutil\n","import argparse\n","import numpy as np\n","from tqdm import tqdm\n","\n","from collections import defaultdict\n","\n","import paddle\n","\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","from ppocr.utils.utility import get_image_file_list\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_rec(config_path, ft_model_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","    global_config['pretrained_model'] = ft_model_path\n","\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'],\n","                                            global_config)\n","\n","    # build model\n","    if hasattr(post_process_class, 'character'):\n","        char_num = len(getattr(post_process_class, 'character'))\n","        if config['Architecture'][\"algorithm\"] in [\"Distillation\",\n","                                                   ]:  # distillation model\n","            for key in config['Architecture'][\"Models\"]:\n","                if config['Architecture']['Models'][key]['Head'][\n","                        'name'] == 'MultiHead':  # for multi head\n","                    out_channels_list = {}\n","                    if config['PostProcess'][\n","                            'name'] == 'DistillationSARLabelDecode':\n","                        char_num = char_num - 2\n","                    out_channels_list['CTCLabelDecode'] = char_num\n","                    out_channels_list['SARLabelDecode'] = char_num + 2\n","                    config['Architecture']['Models'][key]['Head'][\n","                        'out_channels_list'] = out_channels_list\n","                else:\n","                    config['Architecture'][\"Models\"][key][\"Head\"][\n","                        'out_channels'] = char_num\n","        elif config['Architecture']['Head'][\n","                'name'] == 'MultiHead':  # for multi head loss\n","            out_channels_list = {}\n","            if config['PostProcess']['name'] == 'SARLabelDecode':\n","                char_num = char_num - 2\n","            out_channels_list['CTCLabelDecode'] = char_num\n","            out_channels_list['SARLabelDecode'] = char_num + 2\n","            config['Architecture']['Head'][\n","                'out_channels_list'] = out_channels_list\n","        else:  # base rec model\n","            config['Architecture'][\"Head\"]['out_channels'] = char_num\n","\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name in ['RecResizeImg']:\n","            op[op_name]['infer_mode'] = True\n","        elif op_name == 'KeepKeys':\n","            if config['Architecture']['algorithm'] == \"SRN\":\n","                op[op_name]['keep_keys'] = [\n","                    'image', 'encoder_word_pos', 'gsrm_word_pos',\n","                    'gsrm_slf_attn_bias1', 'gsrm_slf_attn_bias2'\n","                ]\n","            elif config['Architecture']['algorithm'] == \"SAR\":\n","                op[op_name]['keep_keys'] = ['image', 'valid_ratio']\n","            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n","                op[op_name][\n","                    'keep_keys'] = ['image', 'valid_ratio', 'word_positons']\n","            else:\n","                op[op_name]['keep_keys'] = ['image']\n","        transforms.append(op)\n","    global_config['infer_mode'] = True\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/crnn_output\"\n","reg_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n","ft_model_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","# Paddle OCR Configs\n","recConfig, recModel, recOPS, recPost = init_rec(reg_yml, ft_model_path)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_arr = []\n","\n","with open(os.path.join(out_path, 'crnn_output.txt'), mode='w') as out_f:\n","    for idx, img_name in enumerate(tqdm(images)):\n","        im_id = img_name.split('/')[-1].replace('.jpg', '')\n","\n","        with open(img_name, 'rb') as f:\n","            img = f.read()\n","            data = {'image': img}\n","        batch = transform(data, recOPS)\n","        images = np.expand_dims(batch[0], axis=0)\n","        images = paddle.to_tensor(images)\n","        preds = recModel(images)\n","        \n","        rec_res = recPost(preds)\n","        formatted_res = rec_res[0][0].replace(' ', '')\n","        out_f.write(f'{os.path.basename(img_name)}\\t{formatted_res}\\n')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":417,"status":"ok","timestamp":1683728517544,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"DBEByfMx2IBk","outputId":"abb721ac-bdb2-4903-8f6b-e64226e04863"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Correctly Recognized Words: 0.8\n","Total Correctly Recognized Words (Case Insensitive): 0.8\n","Total Edit Distance: 8\n","Total Edit Distance (Case Insensitive): 8\n"]}],"source":["# Let's evaluate the HMean for them\n","from rec_eval import total_accuracy, total_edit_distance\n","\n","# Prepare GT\n","gt_dict = {}\n","with open(\"/content/drive/My Drive/CCPD2019/val_rec.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    gt_dict[img_id] = values[1]\n","\n","# Prepare Det\n","det_dict = {}\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/crnn_output/crnn_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    det_dict[img_id] = values[1]\n","\n","gt = []\n","pred = []\n","\n","for key, val in gt_dict.items():\n","  if key in det_dict.keys():\n","    gt.append(val)\n","    pred.append(det_dict[key])\n","\n","total_acc, total_acc_ci = total_accuracy(gt, pred)\n","total_edit, total_edit_ci = total_edit_distance(gt, pred)\n","\n","print(f'Total Correctly Recognized Words: {total_acc}')\n","print(f'Total Correctly Recognized Words (Case Insensitive): {total_acc_ci}')\n","print(f'Total Edit Distance: {total_edit}')\n","print(f'Total Edit Distance (Case Insensitive): {total_edit_ci}')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ttAzKBbBEh2V"},"source":["## Evaluate Fine-tuned EAST + CRNN"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":414,"status":"ok","timestamp":1683729256429,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"vTau0TqGCkGT"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28431,"status":"ok","timestamp":1683729286756,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"dNfIEJ5yErX8","outputId":"5e259654-ef70-4948-9ca9-647af2276934"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/10 14:34:18] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n","[2023/05/10 14:34:18] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:27<00:00,  1.40s/it]\n"]}],"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import yaml\n","import shutil\n","import numpy as np\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","import paddle\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","from ppocr.utils.utility import get_image_file_list\n","\n","\n","__dir__ = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, '..')))\n","\n","\n","def draw_det_res(dt_boxes, img, img_name, save_path):\n","    if len(dt_boxes) > 0:\n","        src_im = img\n","        for box in dt_boxes:\n","            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        save_path = os.path.join(save_path, os.path.basename(img_name))\n","        cv2.imwrite(save_path, src_im)\n","\n","\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in ['.yml', '.yaml'], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, 'rb'), Loader=yaml.Loader)\n","    return config\n","\n","\n","def init_det(config_path, ft_model_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","    global_config['pretrained_model'] = ft_model_path\n","\n","    # build model\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'])\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name == 'KeepKeys':\n","            op[op_name]['keep_keys'] = ['image', 'shape']\n","        transforms.append(op)\n","\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","def init_rec(config_path, ft_model_path):\n","    config = load_config(config_path)\n","    global_config = config['Global']\n","    global_config['pretrained_model'] = ft_model_path\n","\n","    # build post process\n","    post_process_class = build_post_process(config['PostProcess'],\n","                                            global_config)\n","\n","    # build model\n","    if hasattr(post_process_class, 'character'):\n","        char_num = len(getattr(post_process_class, 'character'))\n","        if config['Architecture'][\"algorithm\"] in [\"Distillation\",\n","                                                   ]:  # distillation model\n","            for key in config['Architecture'][\"Models\"]:\n","                if config['Architecture']['Models'][key]['Head'][\n","                        'name'] == 'MultiHead':  # for multi head\n","                    out_channels_list = {}\n","                    if config['PostProcess'][\n","                            'name'] == 'DistillationSARLabelDecode':\n","                        char_num = char_num - 2\n","                    out_channels_list['CTCLabelDecode'] = char_num\n","                    out_channels_list['SARLabelDecode'] = char_num + 2\n","                    config['Architecture']['Models'][key]['Head'][\n","                        'out_channels_list'] = out_channels_list\n","                else:\n","                    config['Architecture'][\"Models\"][key][\"Head\"][\n","                        'out_channels'] = char_num\n","        elif config['Architecture']['Head'][\n","                'name'] == 'MultiHead':  # for multi head loss\n","            out_channels_list = {}\n","            if config['PostProcess']['name'] == 'SARLabelDecode':\n","                char_num = char_num - 2\n","            out_channels_list['CTCLabelDecode'] = char_num\n","            out_channels_list['SARLabelDecode'] = char_num + 2\n","            config['Architecture']['Head'][\n","                'out_channels_list'] = out_channels_list\n","        else:  # base rec model\n","            config['Architecture'][\"Head\"]['out_channels'] = char_num\n","\n","    model = build_model(config['Architecture'])\n","\n","    load_model(config, model)\n","\n","    # create data ops\n","    transforms = []\n","    for op in config['Eval']['dataset']['transforms']:\n","        op_name = list(op)[0]\n","        if 'Label' in op_name:\n","            continue\n","        elif op_name in ['RecResizeImg']:\n","            op[op_name]['infer_mode'] = True\n","        elif op_name == 'KeepKeys':\n","            if config['Architecture']['algorithm'] == \"SRN\":\n","                op[op_name]['keep_keys'] = [\n","                    'image', 'encoder_word_pos', 'gsrm_word_pos',\n","                    'gsrm_slf_attn_bias1', 'gsrm_slf_attn_bias2'\n","                ]\n","            elif config['Architecture']['algorithm'] == \"SAR\":\n","                op[op_name]['keep_keys'] = ['image', 'valid_ratio']\n","            elif config['Architecture']['algorithm'] == \"RobustScanner\":\n","                op[op_name][\n","                    'keep_keys'] = ['image', 'valid_ratio', 'word_positons']\n","            else:\n","                op[op_name]['keep_keys'] = ['image']\n","        transforms.append(op)\n","    global_config['infer_mode'] = True\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_crnn_output\"\n","det_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n","reg_yml = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n","tmp_folder_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_crnn_output/tmp\"\n","\n","det_ft_model_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n","rec_ft_model_path = \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n","\n","if os.path.isdir(tmp_folder_path):\n","    shutil.rmtree(tmp_folder_path)\n","\n","if not os.path.exists(out_path):\n","  os.makedirs(out_path)\n","\n","# Paddle OCR Configs\n","detConfig, detModel, detOPS, detPost = init_det(det_yml, det_ft_model_path)\n","recConfig, recModel, recOPS, recPost = init_rec(reg_yml, rec_ft_model_path)\n","\n","images = glob.glob(os.path.join(img_path, '*'))  # load images\n","\n","output_dict = defaultdict(list)\n","\n","with open(os.path.join(out_path, 'east_crnn_output.txt'), mode='w') as out_f:\n","    for idx, img_name in enumerate(tqdm(images)):\n","        img_id = os.path.basename(img_name)\n","        \n","        # -------------------------------- STAGE I DETECTION ------------------------------\n","        with open(img_name, 'rb') as f:\n","            img = f.read()\n","            data = {'image': img}\n","\n","        batch = transform(data, detOPS)\n","        images = np.expand_dims(batch[0], axis=0)\n","        shape_list = np.expand_dims(batch[1], axis=0)\n","        images = paddle.to_tensor(images)\n","\n","        # forward & post process\n","        preds = detModel(images)\n","        det_res = detPost(preds, shape_list)\n","\n","        # parser boxes if post_result is dict\n","        if isinstance(det_res, dict):\n","            for k in det_res.keys():\n","                boxes = det_res[k][0]['points']\n","        else:\n","            boxes = det_res[0]['points']\n","        \n","        # Crop to patches\n","        ori_img = cv2.imread(img_name)\n","        h, w, c = ori_img.shape\n","        if not os.path.exists(tmp_folder_path):\n","            os.mkdir(tmp_folder_path)\n","\n","        for i, box in enumerate(boxes):\n","            pt = box.tolist()\n","            try:\n","                xs = [x[0] for x in pt]\n","                xs = np.clip(np.array(xs), a_min=0, a_max=w).tolist()\n","                ys = [x[1] for x in pt]\n","                ys = np.clip(np.array(ys), a_min=0, a_max=h).tolist()\n","                minx = min(xs)\n","                miny = min(ys)\n","                maxx = max(xs)\n","                maxy = max(ys)\n","                \n","                if (maxx - minx) <= 0 or (maxy - miny) <= 0:\n","                    print(f'BBOX error occured when cropping image {os.path.basename(img_name)} of {i}-th box')\n","                    print(f'Processed BBOX {minx} {miny} {maxx} {maxy}')\n","                    print(f'Ori BBOX {pt}')\n","                    continue\n","                \n","                crop = ori_img[miny:maxy, minx:maxx]\n","                tmp_img_name = os.path.join('{}/{}_{}.jpg'.format(tmp_folder_path, img_name.split('/')[-1].split('.')[0], str(i)))\n","                cv2.imwrite(tmp_img_name, crop)\n","            except Exception as e:\n","                print(f'Error {e} occured when cropping image {os.path.basename(img_name)} of {i}-th box')\n","                continue\n","        \n","        boxes_len = len(boxes)\n","        tmp_folder_len = len(os.listdir(tmp_folder_path))\n","        if boxes_len == 0 or tmp_folder_len == 0:\n","            print(f'No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}, tmp_len: {tmp_folder_len}')\n","            shutil.rmtree(tmp_folder_path)\n","            continue\n","        \n","        if boxes_len != tmp_folder_len:\n","            print(f'mismatch bbox_len {boxes_len} and tmp_len {tmp_folder_len} for image {os.path.basename(img_name)}')\n","            shutil.rmtree(tmp_folder_path)\n","            continue\n","\n","        # ------------------------- Stage II Recognition ------------------------------\n","        for file in get_image_file_list(tmp_folder_path):\n","            with open(file, 'rb') as f:\n","                img = f.read()\n","                data = {'image': img}\n","            batch = transform(data, recOPS)\n","            images = np.expand_dims(batch[0], axis=0)\n","            images = paddle.to_tensor(images)\n","            preds = recModel(images)\n","                \n","            rec_res = recPost(preds)\n","            formatted_res = rec_res[0][0].replace(' ', '')\n","\n","            b_id = int(file.split('_')[-1].replace('.jpg', ''))\n","            crt_box = boxes[b_id]\n","\n","            output_dict[img_id].append({\n","                'points': crt_box.tolist(),\n","                'transcription': formatted_res,\n","            })\n","\n","        shutil.rmtree(tmp_folder_path)\n","            \n","        out_f.write(f'{img_id}\\t{json.dumps(output_dict[img_id])}\\n')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683729334382,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"rqXZOeC7Eyko","outputId":"94ab9ff9-0548-4e73-f195-3d28c4d62ab3"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.45, Recall: 0.5, HMean: 0.48\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","from det_eval import evaluation\n","from collections import defaultdict\n","\n","eval_config = {\n","    'IOU_CONSTRAINT' : 0.5,\n","    'AREA_PRECISION_CONSTRAINT' : 0.5,\n","    'WORD_SPOTTING' : True,\n","    'PER_SAMPLE_RESULTS': True #Generate per sample results and produce data for visualization,\n","}\n","\n","# Prepare GT\n","gt_dict = defaultdict(list)\n","with open(\"/content/drive/My Drive/CCPD2019/val.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","      gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","# Prepare Det\n","det_dict = defaultdict(list)\n","rec_dict = {}\n","with open(\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/finetuned_results/east_crnn_output/east_crnn_output.txt\", mode='r') as in_txt:\n","  lines = in_txt.readlines()\n","  for line in lines:\n","    line = line.strip()\n","    values = line.split('\\t')\n","    img_id = values[0]\n","    annos = json.loads(values[1])\n","\n","    for anno in annos:\n","      trans = anno[\"transcription\"]\n","      bbox = anno[\"points\"]\n","      xs = [x[0] for x in bbox]\n","      ys = [x[1] for x in bbox]\n","      xmin = min(xs)\n","      xmax = max(xs)\n","      ymin = min(ys)\n","      ymax = max(ys)\n","\n","      width = xmax - xmin\n","      height = ymax - ymin\n","\n","      det_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","resDict = evaluation(gt_dict, det_dict, eval_config)\n","precision, recall, hmean = resDict['method']['precision'], resDict['method']['recall'], resDict['method']['hmean']\n","print('---Overall Metric---')\n","print(f'Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean: {round(hmean, 2)}\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t2vXenkUFpEO"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWvc8QDtGzaIGyWybgpxzN","gpuType":"T4","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
