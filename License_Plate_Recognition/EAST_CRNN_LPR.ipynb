{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 5. Text Detection, Recognition & Spotting on the CCPD 2019 dataset\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3i45jwHyzlSC"},"source":["## Mount GDrive\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2870,"status":"ok","timestamp":1683799461803,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"CSrmdTXqvn9w","outputId":"14f35f4e-4bf9-4365-f81e-3fcae92c3014"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive/\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683799461804,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"6tLWyxVEyo1T","outputId":"622cd780-d2ac-4331-cd67-244d4dd49ad8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive\n","/content/drive/My Drive/CCPD2019\n","CCPD2019.zip  train_crop     train.txt\tval_crop     val.txt\n","train\t      train_rec.txt  val\tval_rec.txt\n"]}],"source":["%cd \"/content/drive/My Drive\"\n","%cd \"CCPD2019\"\n","!ls"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"WGcFIpNrzw28"},"source":["## Install PPOCR\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":31561,"status":"ok","timestamp":1683799493362,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"zsD-t3CsK4zs","outputId":"d1b69571-00d5-4292-be93-84920a1b865a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition\n","fatal: destination path 'PaddleOCR' already exists and is not an empty directory.\n","/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.3)\n","Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.0)\n","Requirement already satisfied: pyclipper in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.3.0.post4)\n","Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.65.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: visualdl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.5.2)\n","Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.0.0)\n","Requirement already satisfied: opencv-python==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.6.0.66)\n","Requirement already satisfied: opencv-contrib-python==4.6.0.66 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.6.0.66)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.29.34)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.9.2)\n","Requirement already satisfied: premailer in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.10.0)\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.0.10)\n","Requirement already satisfied: attrdict in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.0.1)\n","Requirement already satisfied: Polygon3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.0.9.1)\n","Requirement already satisfied: lanms-neo==1.0.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (1.0.2)\n","Requirement already satisfied: PyMuPDF<1.21.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.20.2)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.10.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (8.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (23.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (1.16.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (3.7.1)\n","Requirement already satisfied: bce-python-sdk in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (0.8.83)\n","Requirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.2.4)\n","Requirement already satisfied: Flask-Babel>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.1.0)\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.20.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.27.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.5.3)\n","Requirement already satisfied: x2paddle>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: paddle2onnx>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.0.6)\n","Requirement already satisfied: rarfile in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (4.0)\n","Requirement already satisfied: gradio==3.11.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.11.0)\n","Requirement already satisfied: tritonclient[all] in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.33.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (5.9.5)\n","Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.14.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.8.4)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.95.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.3.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2023.4.0)\n","Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.12.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.24.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.2.0)\n","Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.8.12)\n","Requirement already satisfied: paramiko in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.1.0)\n","Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.17)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.10.7)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.0.6)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.22.0)\n","Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (11.0.3)\n","Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (1.2.0)\n","Requirement already satisfied: cssutils in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (2.6.0)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (5.3.0)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->-r requirements.txt (line 15)) (1.1.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.3.0)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.2)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (8.1.3)\n","Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2.12.1)\n","Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2022.7.1)\n","Collecting protobuf>=3.20.0 (from visualdl->-r requirements.txt (line 8))\n","  Using cached protobuf-4.23.0-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.6.0->visualdl->-r requirements.txt (line 8)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.11.1)\n","Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->-r requirements.txt (line 8)) (0.18.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.4)\n","Requirement already satisfied: python-rapidjson>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.10)\n","  Using cached protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.54.0)\n","Requirement already satisfied: geventhttpclient<=2.0.2,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.1)\n","Requirement already satisfied: gevent>=0.13 in /usr/local/lib/python3.10/dist-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (22.10.2)\n","Requirement already satisfied: brotli in /usr/local/lib/python3.10/dist-packages (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.0.9)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.1.2)\n","Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.26.1)\n","Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.15.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.1.2)\n","Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.3.5)\n","Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (4.0.1)\n","Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (40.0.2)\n","Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.5.0)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.15.1)\n","Requirement already satisfied: zope.event in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (4.6)\n","Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (67.7.2)\n","Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (2.0.2)\n","Requirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.6.2)\n","Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.0.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.21)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.0\n","    Uninstalling protobuf-3.20.0:\n","      Successfully uninstalled protobuf-3.20.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","paddlepaddle 2.4.2 requires protobuf<=3.20.0,>=3.1.0, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: paddlepaddle in /usr/local/lib/python3.10/dist-packages (2.4.2)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (2.27.1)\n","Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.22.4)\n","Collecting protobuf<=3.20.0,>=3.1.0 (from paddlepaddle)\n","  Using cached protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (8.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.16.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n","Requirement already satisfied: astor in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.8.1)\n","Requirement already satisfied: paddle-bfloat==0.1.7 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (0.1.7)\n","Requirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n","Installing collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n","onnx 1.14.0 requires protobuf>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n","tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n","tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.0\n"]},{"data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: levenshtein in /usr/local/lib/python3.10/dist-packages (0.21.0)\n","Requirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein) (3.0.0)\n"]}],"source":["%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/\"\n","!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n","%cd ./PaddleOCR\n","!pip install -r requirements.txt\n","!pip install paddlepaddle\n","!pip install levenshtein"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55062,"status":"ok","timestamp":1683799548418,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"dck-MuVWBH3F","outputId":"6bf642e6-5d88-48d9-92fe-e9aa2e198fbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\n","--2023-05-11 10:04:52--  https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n","Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n","Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.46.61|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33679360 (32M) [application/x-tar]\n","Saving to: ‘det_mv3_east_v2.0_train.tar’\n","\n","det_mv3_east_v2.0_t 100%[===================>]  32.12M  8.44MB/s    in 20s     \n","\n","2023-05-11 10:05:14 (1.60 MB/s) - ‘det_mv3_east_v2.0_train.tar’ saved [33679360/33679360]\n","\n","det_mv3_east_v2.0_train/\n","det_mv3_east_v2.0_train/best_accuracy.pdparams\n","det_mv3_east_v2.0_train/best_accuracy.states\n","det_mv3_east_v2.0_train/best_accuracy.pdopt\n","det_mv3_east_v2.0_train/train.log\n","/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\n","--2023-05-11 10:05:15--  https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n","Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n","Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.46.61|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 51200000 (49M) [application/x-tar]\n","Saving to: ‘rec_mv3_none_bilstm_ctc_v2.0_train.tar’\n","\n","rec_mv3_none_bilstm 100%[===================>]  48.83M  4.36MB/s    in 31s     \n","\n","2023-05-11 10:05:47 (1.59 MB/s) - ‘rec_mv3_none_bilstm_ctc_v2.0_train.tar’ saved [51200000/51200000]\n","\n","rec_mv3_none_bilstm_ctc_v2.0_train/\n","rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.pdopt\n","rec_mv3_none_bilstm_ctc_v2.0_train/.DS_Store\n","rec_mv3_none_bilstm_ctc_v2.0_train/train.log\n","rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.pdparams\n","rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.states\n"]}],"source":["# Uncomment them to download checkpoints for east and crnn to your google drive.\n","\n","%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\"\n","!rm -rf *.tar*\n","!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n","!tar xvf det_mv3_east_v2.0_train.tar\n","\n","%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\"\n","!rm -rf *.tar*\n","!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n","!tar xvf rec_mv3_none_bilstm_ctc_v2.0_train.tar\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jpDTGPnQM1fn"},"source":["## Define Commonly Used Functions\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":865,"status":"ok","timestamp":1683799549261,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"lS4hihgtQZMv","outputId":"76392d53-0c5d-45b1-b557-a7f036134a6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n","applications  doc\t   paddleocr.py  README_ch.md\t   StyleText\n","benchmark     __init__.py  ppocr\t README.md\t   test_tipc\n","configs       LICENSE\t   PPOCRLabel\t requirements.txt  tools\n","deploy\t      MANIFEST.in  ppstructure\t setup.py\t   train.sh\n"]}],"source":["%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n","!ls"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3158,"status":"ok","timestamp":1683799552415,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"shjT6yg-M1fn"},"outputs":[],"source":["import os\n","import cv2\n","import glob\n","import sys\n","import json\n","import yaml\n","import shutil\n","import numpy as np\n","from tqdm import tqdm\n","from collections import defaultdict\n","\n","import paddle\n","from paddle import fluid\n","from ppocr.data import create_operators, transform\n","from ppocr.modeling.architectures import build_model\n","from ppocr.postprocess import build_post_process\n","from ppocr.utils.save_load import load_model\n","from ppocr.utils.utility import get_image_file_list\n","\n","__dir__ = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/PaddleOCR\"\n",")\n","sys.path.append(__dir__)\n","sys.path.append(os.path.abspath(os.path.join(__dir__, \"..\")))\n","\n","from det_eval import evaluation\n","from collections import defaultdict\n","from rec_eval import total_accuracy, total_edit_distance\n","\n","\n","# This is to reset dygraph\n","def reset_dygraph():\n","    fluid.dygraph.disable_dygraph()\n","    fluid.dygraph.enable_dygraph()\n","\n","\n","# HMean for text detection and spotting\n","def det_eval(gt_path, det_path, eval_config):\n","    # Prepare GT\n","    gt_dict = defaultdict(list)\n","    with open(gt_path, mode=\"r\") as in_txt:\n","        lines = in_txt.readlines()\n","        for line in lines:\n","            line = line.strip()\n","            values = line.split(\"\\t\")\n","            img_id = values[0]\n","            annos = json.loads(values[1])\n","\n","            for anno in annos:\n","                trans = anno[\"transcription\"]\n","                bbox = anno[\"points\"]\n","                xs = [x[0] for x in bbox]\n","                ys = [x[1] for x in bbox]\n","                xmin = min(xs)\n","                xmax = max(xs)\n","                ymin = min(ys)\n","                ymax = max(ys)\n","                gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n","\n","    # Prepare Det\n","    det_dict = defaultdict(list)\n","    with open(det_path, mode=\"r\") as in_txt:\n","        lines = in_txt.readlines()\n","        for line in lines:\n","            line = line.strip()\n","            values = line.split(\"\\t\")\n","            img_id = values[0]\n","            annos = json.loads(values[1])\n","\n","            for anno in annos:\n","                bbox = anno[\"points\"]\n","                xs = [x[0] for x in bbox]\n","                ys = [x[1] for x in bbox]\n","                xmin = min(xs)\n","                xmax = max(xs)\n","                ymin = min(ys)\n","                ymax = max(ys)\n","\n","                width = xmax - xmin\n","                height = ymax - ymin\n","\n","                pred_entry = [xmin, ymin, xmax, ymax]\n","\n","                if eval_config[\"WORD_SPOTTING\"]:\n","                    trans = anno[\"transcription\"]\n","                    pred_entry.append(trans)\n","\n","                det_dict[img_id].append(pred_entry)\n","\n","    resDict = evaluation(gt_dict, det_dict, eval_config)\n","    return resDict\n","\n","\n","# Accuracy and Edit Distance for text recognition - data preparation\n","def data_prep_rec_eval(gt_path, det_path):\n","    # Prepare GT\n","    gt_dict = {}\n","    with open(gt_path, mode=\"r\") as in_txt:\n","        lines = in_txt.readlines()\n","        for line in lines:\n","            line = line.strip()\n","            values = line.split(\"\\t\")\n","            img_id = values[0]\n","            gt_dict[img_id] = values[1]\n","\n","    # Prepare Det\n","    det_dict = {}\n","    with open(det_path, mode=\"r\") as in_txt:\n","        lines = in_txt.readlines()\n","        for line in lines:\n","            line = line.strip()\n","            values = line.split(\"\\t\")\n","            img_id = values[0]\n","            det_dict[img_id] = values[1]\n","\n","    gt = []\n","    pred = []\n","\n","    for key, val in gt_dict.items():\n","        if key in det_dict.keys():\n","            gt.append(val)\n","            pred.append(det_dict[key])\n","\n","    return gt, pred\n","\n","\n","# Draw detection result from PaddleOCR\n","def draw_det_res(dt_boxes, img, img_name, save_path):\n","    if len(dt_boxes) > 0:\n","        src_im = img\n","        for box in dt_boxes:\n","            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n","            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n","        if not os.path.exists(save_path):\n","            os.makedirs(save_path)\n","        save_path = os.path.join(save_path, os.path.basename(img_name))\n","        cv2.imwrite(save_path, src_im)\n","\n","\n","# Load PaddleOCR config\n","def load_config(file_path):\n","    \"\"\"\n","    Load config from yml/yaml file.\n","    Args:\n","        file_path (str): Path of the config file to be loaded.\n","    Returns: global config\n","    \"\"\"\n","    _, ext = os.path.splitext(file_path)\n","    assert ext in [\".yml\", \".yaml\"], \"only support yaml files for now\"\n","    config = yaml.load(open(file_path, \"rb\"), Loader=yaml.Loader)\n","    return config\n","\n","\n","# Init detection model of PaddleOCR\n","def init_det(config_path, ft_model_path=None):\n","    config = load_config(config_path)\n","    global_config = config[\"Global\"]\n","    if ft_model_path != None:\n","        global_config[\"pretrained_model\"] = ft_model_path\n","\n","    # build model\n","    model = build_model(config[\"Architecture\"])\n","\n","    load_model(config, model)\n","    # build post process\n","    post_process_class = build_post_process(config[\"PostProcess\"])\n","\n","    # create data ops\n","    transforms = []\n","    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n","        op_name = list(op)[0]\n","        if \"Label\" in op_name:\n","            continue\n","        elif op_name == \"KeepKeys\":\n","            op[op_name][\"keep_keys\"] = [\"image\", \"shape\"]\n","        transforms.append(op)\n","\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","# Carry out text detection using PaddleOCR\n","def det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name, ft_model_path=None):\n","    if not os.path.exists(out_path):\n","        os.makedirs(out_path)\n","\n","    if not os.path.exists(vis_path):\n","        os.makedirs(vis_path)\n","\n","    # Paddle OCR Configs\n","    detConfig, detModel, detOPS, detPost = init_det(det_yml, ft_model_path)\n","\n","    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n","\n","    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n","        for idx, img_name in enumerate(tqdm(images)):\n","            bbox_outputs = []\n","            with open(img_name, \"rb\") as f:\n","                img = f.read()\n","                data = {\"image\": img}\n","\n","            batch = transform(data, detOPS)\n","            images = np.expand_dims(batch[0], axis=0)\n","            shape_list = np.expand_dims(batch[1], axis=0)\n","            images = paddle.to_tensor(images)\n","\n","            # forward & post process\n","            preds = detModel(images)\n","            det_res = detPost(preds, shape_list)\n","\n","            # parser boxes if post_result is dict\n","            if isinstance(det_res, dict):\n","                for k in det_res.keys():\n","                    boxes = det_res[k][0][\"points\"]\n","            else:\n","                boxes = det_res[0][\"points\"]\n","\n","            # write predictions to images\n","            draw_det_res(boxes, cv2.imread(img_name), img_name, vis_path)\n","\n","            boxes_len = len(boxes)\n","            if boxes_len == 0:\n","                print(\n","                    f\"No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}\"\n","                )\n","                continue\n","            else:\n","                for box in boxes:\n","                    box_list = box.tolist()\n","\n","                    current_res_dict = {\"points\": box_list}\n","                    bbox_outputs.append(current_res_dict)\n","\n","            out_f.write(f\"{os.path.basename(img_name)}\\t{json.dumps(bbox_outputs)}\\n\")\n","\n","\n","# Init recognition model of PaddleOCR\n","def init_rec(config_path, ft_model_path=None):\n","    config = load_config(config_path)\n","    global_config = config[\"Global\"]\n","    if ft_model_path != None:\n","        global_config[\"pretrained_model\"] = ft_model_path\n","\n","    # build post process\n","    post_process_class = build_post_process(config[\"PostProcess\"], global_config)\n","\n","    # build model\n","    if hasattr(post_process_class, \"character\"):\n","        char_num = len(getattr(post_process_class, \"character\"))\n","        if config[\"Architecture\"][\"algorithm\"] in [\n","            \"Distillation\",\n","        ]:  # distillation model\n","            for key in config[\"Architecture\"][\"Models\"]:\n","                if (\n","                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\"name\"] == \"MultiHead\"\n","                ):  # for multi head\n","                    out_channels_list = {}\n","                    if config[\"PostProcess\"][\"name\"] == \"DistillationSARLabelDecode\":\n","                        char_num = char_num - 2\n","                    out_channels_list[\"CTCLabelDecode\"] = char_num\n","                    out_channels_list[\"SARLabelDecode\"] = char_num + 2\n","                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n","                        \"out_channels_list\"\n","                    ] = out_channels_list\n","                else:\n","                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n","                        \"out_channels\"\n","                    ] = char_num\n","        elif (\n","            config[\"Architecture\"][\"Head\"][\"name\"] == \"MultiHead\"\n","        ):  # for multi head loss\n","            out_channels_list = {}\n","            if config[\"PostProcess\"][\"name\"] == \"SARLabelDecode\":\n","                char_num = char_num - 2\n","            out_channels_list[\"CTCLabelDecode\"] = char_num\n","            out_channels_list[\"SARLabelDecode\"] = char_num + 2\n","            config[\"Architecture\"][\"Head\"][\"out_channels_list\"] = out_channels_list\n","        else:  # base rec model\n","            config[\"Architecture\"][\"Head\"][\"out_channels\"] = char_num\n","\n","    model = build_model(config[\"Architecture\"])\n","\n","    load_model(config, model)\n","\n","    # create data ops\n","    transforms = []\n","    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n","        op_name = list(op)[0]\n","        if \"Label\" in op_name:\n","            continue\n","        elif op_name in [\"RecResizeImg\"]:\n","            op[op_name][\"infer_mode\"] = True\n","        elif op_name == \"KeepKeys\":\n","            if config[\"Architecture\"][\"algorithm\"] == \"SRN\":\n","                op[op_name][\"keep_keys\"] = [\n","                    \"image\",\n","                    \"encoder_word_pos\",\n","                    \"gsrm_word_pos\",\n","                    \"gsrm_slf_attn_bias1\",\n","                    \"gsrm_slf_attn_bias2\",\n","                ]\n","            elif config[\"Architecture\"][\"algorithm\"] == \"SAR\":\n","                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\"]\n","            elif config[\"Architecture\"][\"algorithm\"] == \"RobustScanner\":\n","                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\", \"word_positons\"]\n","            else:\n","                op[op_name][\"keep_keys\"] = [\"image\"]\n","        transforms.append(op)\n","    global_config[\"infer_mode\"] = True\n","    ops = create_operators(transforms, global_config)\n","\n","    model.eval()\n","    return config, model, ops, post_process_class\n","\n","\n","# Carry out text recognition using PaddleOCR\n","def rec_ppocr(out_path, reg_yml, img_path, out_txt_name, ft_model_path=None):\n","    if not os.path.exists(out_path):\n","        os.makedirs(out_path)\n","\n","    # Paddle OCR Configs\n","    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, ft_model_path)\n","\n","    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n","\n","    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n","        for idx, img_name in enumerate(tqdm(images)):\n","            with open(img_name, \"rb\") as f:\n","                img = f.read()\n","                data = {\"image\": img}\n","            batch = transform(data, recOPS)\n","            images = np.expand_dims(batch[0], axis=0)\n","            images = paddle.to_tensor(images)\n","            preds = recModel(images)\n","\n","            rec_res = recPost(preds)\n","            formatted_res = rec_res[0][0].replace(\" \", \"\")\n","            out_f.write(f\"{os.path.basename(img_name)}\\t{formatted_res}\\n\")\n","\n","\n","# Chaining text detection and recognition end-to-end using PaddleOCR\n","def spot_ppocr(\n","    tmp_folder_path,\n","    out_path,\n","    det_yml,\n","    reg_yml,\n","    img_path,\n","    out_txt_name,\n","    det_ft_model_path=None,\n","    rec_ft_model_path=None,\n","):\n","    if os.path.isdir(tmp_folder_path):\n","        shutil.rmtree(tmp_folder_path)\n","\n","    if not os.path.exists(out_path):\n","        os.makedirs(out_path)\n","\n","    # Paddle OCR Configs\n","    detConfig, detModel, detOPS, detPost = init_det(det_yml, det_ft_model_path)\n","    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, rec_ft_model_path)\n","\n","    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n","\n","    output_dict = defaultdict(list)\n","\n","    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n","        for idx, img_name in enumerate(tqdm(images)):\n","            img_id = os.path.basename(img_name)\n","\n","            # -------------------------------- STAGE I DETECTION ------------------------------\n","            with open(img_name, \"rb\") as f:\n","                img = f.read()\n","                data = {\"image\": img}\n","\n","            batch = transform(data, detOPS)\n","            images = np.expand_dims(batch[0], axis=0)\n","            shape_list = np.expand_dims(batch[1], axis=0)\n","            images = paddle.to_tensor(images)\n","\n","            # forward & post process\n","            preds = detModel(images)\n","            det_res = detPost(preds, shape_list)\n","\n","            # parser boxes if post_result is dict\n","            if isinstance(det_res, dict):\n","                for k in det_res.keys():\n","                    boxes = det_res[k][0][\"points\"]\n","            else:\n","                boxes = det_res[0][\"points\"]\n","\n","            # Crop to patches\n","            ori_img = cv2.imread(img_name)\n","            h, w, c = ori_img.shape\n","            if not os.path.exists(tmp_folder_path):\n","                os.mkdir(tmp_folder_path)\n","\n","            for i, box in enumerate(boxes):\n","                pt = box.tolist()\n","                try:\n","                    xs = [x[0] for x in pt]\n","                    xs = np.clip(np.array(xs), a_min=0, a_max=w).tolist()\n","                    ys = [x[1] for x in pt]\n","                    ys = np.clip(np.array(ys), a_min=0, a_max=h).tolist()\n","                    minx = min(xs)\n","                    miny = min(ys)\n","                    maxx = max(xs)\n","                    maxy = max(ys)\n","\n","                    if (maxx - minx) <= 0 or (maxy - miny) <= 0:\n","                        print(\n","                            \"BBOX error occured when cropping image\"\n","                            f\" {os.path.basename(img_name)} of {i}-th box\"\n","                        )\n","                        print(f\"Processed BBOX {minx} {miny} {maxx} {maxy}\")\n","                        print(f\"Ori BBOX {pt}\")\n","                        continue\n","\n","                    crop = ori_img[miny:maxy, minx:maxx]\n","                    tmp_img_name = os.path.join(\n","                        \"{}/{}_{}.jpg\".format(\n","                            tmp_folder_path,\n","                            img_name.split(\"/\")[-1].split(\".\")[0],\n","                            str(i),\n","                        )\n","                    )\n","                    cv2.imwrite(tmp_img_name, crop)\n","                except Exception as e:\n","                    print(\n","                        f\"Error {e} occured when cropping image\"\n","                        f\" {os.path.basename(img_name)} of {i}-th box\"\n","                    )\n","                    continue\n","\n","            boxes_len = len(boxes)\n","            tmp_folder_len = len(os.listdir(tmp_folder_path))\n","            if boxes_len == 0 or tmp_folder_len == 0:\n","                print(\n","                    f\"No output for {os.path.basename(img_name)}, bbox_len:\"\n","                    f\" {boxes_len}, tmp_len: {tmp_folder_len}\"\n","                )\n","                shutil.rmtree(tmp_folder_path)\n","                continue\n","\n","            if boxes_len != tmp_folder_len:\n","                print(\n","                    f\"mismatch bbox_len {boxes_len} and tmp_len {tmp_folder_len} for\"\n","                    f\" image {os.path.basename(img_name)}\"\n","                )\n","                shutil.rmtree(tmp_folder_path)\n","                continue\n","\n","            # ------------------------- Stage II Recognition ------------------------------\n","            for file in get_image_file_list(tmp_folder_path):\n","                with open(file, \"rb\") as f:\n","                    img = f.read()\n","                    data = {\"image\": img}\n","                batch = transform(data, recOPS)\n","                images = np.expand_dims(batch[0], axis=0)\n","                images = paddle.to_tensor(images)\n","                preds = recModel(images)\n","\n","                rec_res = recPost(preds)\n","                formatted_res = rec_res[0][0].replace(\" \", \"\")\n","\n","                b_id = int(file.split(\"_\")[-1].replace(\".jpg\", \"\"))\n","                crt_box = boxes[b_id]\n","\n","                output_dict[img_id].append(\n","                    {\n","                        \"points\": crt_box.tolist(),\n","                        \"transcription\": formatted_res,\n","                    }\n","                )\n","\n","            shutil.rmtree(tmp_folder_path)\n","\n","            out_f.write(f\"{img_id}\\t{json.dumps(output_dict[img_id])}\\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qkVCWdZvPxq9"},"source":["## Text Detection Using Pre-trained EAST\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683799552416,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"9WzRLbMjM1fr"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33558,"status":"ok","timestamp":1683799585955,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"nRhS2KSZcheZ","outputId":"de9f5adf-484f-441f-a580-7b4d78950119"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:05:52] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n"]}],"source":["out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_output\"\n",")\n","vis_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_output/vis\"\n",")\n","det_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_txt_name = \"east_output\"\n","\n","det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2tV2TdaUli2F"},"source":["## Text Detection Evaluation\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1683799585956,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"lpDrLo97nYaE","outputId":"41caa3b7-7361-48e7-dae5-c0f17b8e9441"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.06, Recall: 0.25, HMean: 0.1\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","eval_config = {\n","    \"IOU_CONSTRAINT\": 0.5,\n","    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n","    \"WORD_SPOTTING\": False,\n","}\n","\n","gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_output/east_output.txt\"\n",")\n","resDict = det_eval(gt_path, det_path, eval_config)\n","precision, recall, hmean = (\n","    resDict[\"method\"][\"precision\"],\n","    resDict[\"method\"][\"recall\"],\n","    resDict[\"method\"][\"hmean\"],\n",")\n","\n","print(\"---Overall Metric---\")\n","print(\n","    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n","    f\" {round(hmean, 2)}\\n\"\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gwzLm-WC0pMi"},"source":["## Text Recognition Using Pre-trained CRNN\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5708,"status":"ok","timestamp":1683799591643,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"fBIKUCHn0uOe","outputId":"2c29369f-1d19-4de7-c7dd-845a9e2bc617"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:06:25] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n","[2023/05/11 10:06:25] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n","[2023/05/11 10:06:25] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:05<00:00,  3.96it/s]\n"]}],"source":["out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/crnn_output\"\n",")\n","reg_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n","out_txt_name = \"crnn_output\"\n","\n","rec_ppocr(out_path, reg_yml, img_path, out_txt_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AzXgaEma79ob"},"source":["## Text Recognition Evaluation\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683799591643,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"mRYFc5Bi5cMP","outputId":"0d7f8996-65f3-46fb-e0c0-769d03f53481"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Correctly Recognized Words: 0\n","Total Correctly Recognized Words (Case Insensitive): 0\n","Accuracy: 0.0 %\n","Accuracy (Case Insensitive): 0.0 %\n","Total Edit Distance: 352\n","Total Edit Distance (Case Insensitive): 346\n"]}],"source":["# Let's evaluate the Accuracy for them\n","gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/crnn_output/crnn_output.txt\"\n",")\n","gt, pred = data_prep_rec_eval(gt_path, det_path)\n","total_crw, total_crw_ci = total_accuracy(gt, pred)\n","total_edit, total_edit_ci = total_edit_distance(gt, pred)\n","\n","print(f\"Total Correctly Recognized Words: {total_crw}\")\n","print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n","print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n","print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n","print(f\"Total Edit Distance: {total_edit}\")\n","print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8xtpP0rz-_CO"},"source":["## Text Spotting Using Pre-trained EAST + CRNN\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683799591644,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"67LlRxZSM1ft"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27766,"status":"ok","timestamp":1683799619406,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"DEkm-Rkh--DK","outputId":"2fe314f5-a059-43b9-807c-8cbe70449835"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:06:31] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n","[2023/05/11 10:06:31] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n","[2023/05/11 10:06:31] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n","[2023/05/11 10:06:31] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:26<00:00,  1.35s/it]\n"]}],"source":["tmp_folder_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_crnn_output/tmp\"\n",")\n","out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_crnn_output\"\n",")\n","det_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",")\n","reg_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_txt_name = \"east_crnn_output\"\n","\n","spot_ppocr(tmp_folder_path, out_path, det_yml, reg_yml, img_path, out_txt_name)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"T4xQ7K2t9z9I"},"source":["## Text Spotting Evaluation\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683799619406,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"FUrvo2rT915O","outputId":"97363efe-9968-4f1f-e9b6-ee32497133a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.0, Recall: 0.0, HMean: 0\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","eval_config = {\n","    \"IOU_CONSTRAINT\": 0.5,\n","    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n","    \"WORD_SPOTTING\": True,\n","}\n","\n","gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/pretrained_results/east_crnn_output/east_crnn_output.txt\"\n",")\n","resDict = det_eval(gt_path, det_path, eval_config)\n","precision, recall, hmean = (\n","    resDict[\"method\"][\"precision\"],\n","    resDict[\"method\"][\"recall\"],\n","    resDict[\"method\"][\"hmean\"],\n",")\n","\n","print(\"---Overall Metric---\")\n","print(\n","    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n","    f\" {round(hmean, 2)}\\n\"\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YK9u3dJ3FmKL"},"source":["## Fine-tuning EAST\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683799619407,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"7r65AU7aFp-B"},"outputs":[],"source":["# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n","# Please set Global.use_gpu=True if you are running on a machine with GPU\n","# Fine-tuning for 100 epochs took 4 mins 29 secs on V100\n","\n","# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\" \\\n","# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\" Global.use_gpu=False"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xUlpKV9-y-lM"},"source":["## Fine-tuning CRNN\n"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683799619407,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"AUqMuLg8I17_"},"outputs":[],"source":["# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n","# Please set Global.use_gpu=True if you are running on a machine with GPU\n","# Fine-tuning for 200 epochs took 5 mins 47 secs on V100\n","\n","# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\" \\\n","# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\" Global.use_gpu=False"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2jhnx3NmzDwX"},"source":["## Evaluate Fine-tuned EAST\n"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683799619407,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"y_dxujK16_sZ"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26065,"status":"ok","timestamp":1683799645468,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"ezu45JVlzLp6","outputId":"49d5e902-2f45-4b87-96cb-791068423f4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:06:59] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:24<00:00,  1.24s/it]\n"]}],"source":["out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_output\"\n",")\n","vis_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_output/vis\"\n",")\n","det_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_txt_name = \"east_output\"\n","ft_model_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",")\n","\n","det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name, ft_model_path)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1683799645469,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"lXH2SiLu2Dq7","outputId":"0142f058-8099-4d59-e146-c07e1303cc33"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.91, Recall: 1.0, HMean: 0.95\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","eval_config = {\n","    \"IOU_CONSTRAINT\": 0.5,\n","    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n","    \"WORD_SPOTTING\": False,\n","}\n","\n","gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_output/east_output.txt\"\n",")\n","resDict = det_eval(gt_path, det_path, eval_config)\n","precision, recall, hmean = (\n","    resDict[\"method\"][\"precision\"],\n","    resDict[\"method\"][\"recall\"],\n","    resDict[\"method\"][\"hmean\"],\n",")\n","\n","print(\"---Overall Metric---\")\n","print(\n","    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n","    f\" {round(hmean, 2)}\\n\"\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-zVcdOzHzHI-"},"source":["## Evaluate Fine-tuned CRNN\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2058,"status":"ok","timestamp":1683799647507,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"KFFf-JGQzIbk","outputId":"d306a230-ff38-4b08-e7ad-0c2cff5fd053"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:07:25] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:00<00:00, 25.19it/s]\n"]}],"source":["out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/crnn_output\"\n",")\n","reg_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n","out_txt_name = \"crnn_output\"\n","ft_model_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",")\n","\n","rec_ppocr(out_path, reg_yml, img_path, out_txt_name, ft_model_path)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683799647508,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"DBEByfMx2IBk","outputId":"1ac1d8b1-0894-4fdd-935f-c7c6a78a21e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total Correctly Recognized Words: 16\n","Total Correctly Recognized Words (Case Insensitive): 16\n","Accuracy: 80.0 %\n","Accuracy (Case Insensitive): 80.0 %\n","Total Edit Distance: 8\n","Total Edit Distance (Case Insensitive): 8\n"]}],"source":["# Let's evaluate the Accuracy for them\n","gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/crnn_output/crnn_output.txt\"\n",")\n","gt, pred = data_prep_rec_eval(gt_path, det_path)\n","total_crw, total_crw_ci = total_accuracy(gt, pred)\n","total_edit, total_edit_ci = total_edit_distance(gt, pred)\n","\n","print(f\"Total Correctly Recognized Words: {total_crw}\")\n","print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n","print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n","print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n","print(f\"Total Edit Distance: {total_edit}\")\n","print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ttAzKBbBEh2V"},"source":["## Evaluate Fine-tuned EAST + CRNN\n"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683799647508,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"vTau0TqGCkGT"},"outputs":[],"source":["reset_dygraph()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24377,"status":"ok","timestamp":1683799671880,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"dNfIEJ5yErX8","outputId":"c49150aa-7ba5-4650-d036-b164b2521720"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2023/05/11 10:07:26] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n","[2023/05/11 10:07:27] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 20/20 [00:24<00:00,  1.20s/it]\n"]}],"source":["tmp_folder_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_crnn_output/tmp\"\n",")\n","out_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_crnn_output\"\n",")\n","det_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",")\n","reg_yml = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",")\n","img_path = \"/content/drive/My Drive/CCPD2019/val\"\n","out_txt_name = \"east_crnn_output\"\n","det_ft_model_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",")\n","rec_ft_model_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",")\n","\n","spot_ppocr(\n","    tmp_folder_path,\n","    out_path,\n","    det_yml,\n","    reg_yml,\n","    img_path,\n","    out_txt_name,\n","    det_ft_model_path,\n","    rec_ft_model_path,\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1683799671880,"user":{"displayName":"Chun Chet Ng","userId":"03243561045656893985"},"user_tz":-480},"id":"rqXZOeC7Eyko","outputId":"1122c25b-9fae-4fb9-b75b-530e1d7ec50e"},"outputs":[{"name":"stdout","output_type":"stream","text":["---Overall Metric---\n","Precision: 0.45, Recall: 0.5, HMean: 0.48\n","\n"]}],"source":["# Let's evaluate the HMean for them\n","eval_config = {\n","    \"IOU_CONSTRAINT\": 0.5,\n","    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n","    \"WORD_SPOTTING\": True,\n","}\n","\n","gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n","det_path = (\n","    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n","    \"License_Plate_Recognition/finetuned_results/east_crnn_output/east_crnn_output.txt\"\n",")\n","resDict = det_eval(gt_path, det_path, eval_config)\n","precision, recall, hmean = (\n","    resDict[\"method\"][\"precision\"],\n","    resDict[\"method\"][\"recall\"],\n","    resDict[\"method\"][\"hmean\"],\n",")\n","\n","print(\"---Overall Metric---\")\n","print(\n","    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n","    f\" {round(hmean, 2)}\\n\"\n",")"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
