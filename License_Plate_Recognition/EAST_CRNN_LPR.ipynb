{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3i45jwHyzlSC"
   },
   "source": [
    "## Mount GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3024,
     "status": "ok",
     "timestamp": 1683728352635,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "CSrmdTXqvn9w",
    "outputId": "43cff59f-56f2-4f17-a483-894cbd767f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683728352636,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "6tLWyxVEyo1T",
    "outputId": "45537d6e-402f-4655-e680-5d07d1ffa765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive\n",
      "/content/drive/My Drive/CCPD2019\n",
      "CCPD2019.zip  train_crop     train.txt\tval_crop     val.txt\n",
      "train\t      train_rec.txt  val\tval_rec.txt\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive\"\n",
    "%cd \"CCPD2019\"\n",
    "!ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "WGcFIpNrzw28"
   },
   "source": [
    "## Install PPOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 35418,
     "status": "ok",
     "timestamp": 1683728388049,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "zsD-t3CsK4zs",
    "outputId": "963c687f-f034-4cba-d4c8-60090341aed5"
   },
   "outputs": [],
   "source": [
    "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/\"\n",
    "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
    "%cd ./PaddleOCR\n",
    "!pip install -r requirements.txt\n",
    "!pip install paddlepaddle\n",
    "!pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683728388050,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "dck-MuVWBH3F"
   },
   "outputs": [],
   "source": [
    "# Uncomment them to download checkpoints for east and crnn to your google drive.\n",
    "\n",
    "# %cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\"\n",
    "# !rm -rf *.tar*\n",
    "# !wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n",
    "# !tar xvf det_mv3_east_v2.0_train.tar\n",
    "\n",
    "# %cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\"v\n",
    "# !rm -rf *.tar*\n",
    "# !wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n",
    "# !tar xvf rec_mv3_none_bilstm_ctc_v2.0_train.tar\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Commonly Used Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import paddle\n",
    "from paddle import fluid\n",
    "from ppocr.data import create_operators, transform\n",
    "from ppocr.modeling.architectures import build_model\n",
    "from ppocr.postprocess import build_post_process\n",
    "from ppocr.utils.save_load import load_model\n",
    "from ppocr.utils.utility import get_image_file_list\n",
    "\n",
    "from det_eval import evaluation\n",
    "from collections import defaultdict\n",
    "\n",
    "from rec_eval import total_accuracy, total_edit_distance\n",
    "\n",
    "__dir__ = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/PaddleOCR\"\n",
    ")\n",
    "sys.path.append(__dir__)\n",
    "sys.path.append(os.path.abspath(os.path.join(__dir__, \"..\")))\n",
    "\n",
    "\n",
    "# This is to reset dygraph\n",
    "def reset_dygraph():\n",
    "    fluid.dygraph.disable_dygraph()\n",
    "    fluid.dygraph.enable_dygraph()\n",
    "\n",
    "\n",
    "# HMean for text detection and spotting\n",
    "def det_eval(gt_path, det_path, eval_config):\n",
    "    # Prepare GT\n",
    "    gt_dict = defaultdict(list)\n",
    "    with open(gt_path, mode=\"r\") as in_txt:\n",
    "        lines = in_txt.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            values = line.split(\"\\t\")\n",
    "            img_id = values[0]\n",
    "            annos = json.loads(values[1])\n",
    "\n",
    "            for anno in annos:\n",
    "                trans = anno[\"transcription\"]\n",
    "                bbox = anno[\"points\"]\n",
    "                xs = [x[0] for x in bbox]\n",
    "                ys = [x[1] for x in bbox]\n",
    "                xmin = min(xs)\n",
    "                xmax = max(xs)\n",
    "                ymin = min(ys)\n",
    "                ymax = max(ys)\n",
    "                gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n",
    "\n",
    "    # Prepare Det\n",
    "    det_dict = defaultdict(list)\n",
    "    with open(det_path, mode=\"r\") as in_txt:\n",
    "        lines = in_txt.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            values = line.split(\"\\t\")\n",
    "            img_id = values[0]\n",
    "            annos = json.loads(values[1])\n",
    "\n",
    "            for anno in annos:\n",
    "                bbox = anno[\"points\"]\n",
    "                xs = [x[0] for x in bbox]\n",
    "                ys = [x[1] for x in bbox]\n",
    "                xmin = min(xs)\n",
    "                xmax = max(xs)\n",
    "                ymin = min(ys)\n",
    "                ymax = max(ys)\n",
    "\n",
    "                width = xmax - xmin\n",
    "                height = ymax - ymin\n",
    "\n",
    "                pred_entry = [xmin, ymin, xmax, ymax]\n",
    "\n",
    "                if eval_config[\"WORD_SPOTTING\"]:\n",
    "                    trans = anno[\"transcription\"]\n",
    "                    pred_entry.append(trans)\n",
    "\n",
    "                det_dict[img_id].append(pred_entry)\n",
    "\n",
    "    resDict = evaluation(gt_dict, det_dict, eval_config)\n",
    "    return resDict\n",
    "\n",
    "\n",
    "# Accuracy and Edit Distance for text recognition - data preparation\n",
    "def data_prep_rec_eval(gt_path, det_path):\n",
    "    # Prepare GT\n",
    "    gt_dict = {}\n",
    "    with open(gt_path, mode=\"r\") as in_txt:\n",
    "        lines = in_txt.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            values = line.split(\"\\t\")\n",
    "            img_id = values[0]\n",
    "            gt_dict[img_id] = values[1]\n",
    "\n",
    "    # Prepare Det\n",
    "    det_dict = {}\n",
    "    with open(det_path, mode=\"r\") as in_txt:\n",
    "        lines = in_txt.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            values = line.split(\"\\t\")\n",
    "            img_id = values[0]\n",
    "            det_dict[img_id] = values[1]\n",
    "\n",
    "    gt = []\n",
    "    pred = []\n",
    "\n",
    "    for key, val in gt_dict.items():\n",
    "        if key in det_dict.keys():\n",
    "            gt.append(val)\n",
    "            pred.append(det_dict[key])\n",
    "\n",
    "    return gt, pred\n",
    "\n",
    "\n",
    "# Draw detection result from PaddleOCR\n",
    "def draw_det_res(dt_boxes, img, img_name, save_path):\n",
    "    if len(dt_boxes) > 0:\n",
    "        src_im = img\n",
    "        for box in dt_boxes:\n",
    "            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        save_path = os.path.join(save_path, os.path.basename(img_name))\n",
    "        cv2.imwrite(save_path, src_im)\n",
    "\n",
    "\n",
    "# Load PaddleOCR config\n",
    "def load_config(file_path):\n",
    "    \"\"\"\n",
    "    Load config from yml/yaml file.\n",
    "    Args:\n",
    "        file_path (str): Path of the config file to be loaded.\n",
    "    Returns: global config\n",
    "    \"\"\"\n",
    "    _, ext = os.path.splitext(file_path)\n",
    "    assert ext in [\".yml\", \".yaml\"], \"only support yaml files for now\"\n",
    "    config = yaml.load(open(file_path, \"rb\"), Loader=yaml.Loader)\n",
    "    return config\n",
    "\n",
    "\n",
    "# Init detection model of PaddleOCR\n",
    "def init_det(config_path, ft_model_path=None):\n",
    "    config = load_config(config_path)\n",
    "    global_config = config[\"Global\"]\n",
    "    if ft_model_path != None:\n",
    "        global_config[\"pretrained_model\"] = ft_model_path\n",
    "\n",
    "    # build model\n",
    "    model = build_model(config[\"Architecture\"])\n",
    "\n",
    "    load_model(config, model)\n",
    "    # build post process\n",
    "    post_process_class = build_post_process(config[\"PostProcess\"])\n",
    "\n",
    "    # create data ops\n",
    "    transforms = []\n",
    "    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n",
    "        op_name = list(op)[0]\n",
    "        if \"Label\" in op_name:\n",
    "            continue\n",
    "        elif op_name == \"KeepKeys\":\n",
    "            op[op_name][\"keep_keys\"] = [\"image\", \"shape\"]\n",
    "        transforms.append(op)\n",
    "\n",
    "    ops = create_operators(transforms, global_config)\n",
    "\n",
    "    model.eval()\n",
    "    return config, model, ops, post_process_class\n",
    "\n",
    "\n",
    "# Carry out text detection using PaddleOCR\n",
    "def det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name, ft_model_path=None):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    if not os.path.exists(vis_path):\n",
    "        os.makedirs(vis_path)\n",
    "\n",
    "    # Paddle OCR Configs\n",
    "    detConfig, detModel, detOPS, detPost = init_det(det_yml, ft_model_path)\n",
    "\n",
    "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
    "\n",
    "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
    "        for idx, img_name in enumerate(tqdm(images)):\n",
    "            bbox_outputs = []\n",
    "            with open(img_name, \"rb\") as f:\n",
    "                img = f.read()\n",
    "                data = {\"image\": img}\n",
    "\n",
    "            batch = transform(data, detOPS)\n",
    "            images = np.expand_dims(batch[0], axis=0)\n",
    "            shape_list = np.expand_dims(batch[1], axis=0)\n",
    "            images = paddle.to_tensor(images)\n",
    "\n",
    "            # forward & post process\n",
    "            preds = detModel(images)\n",
    "            det_res = detPost(preds, shape_list)\n",
    "\n",
    "            # parser boxes if post_result is dict\n",
    "            if isinstance(det_res, dict):\n",
    "                for k in det_res.keys():\n",
    "                    boxes = det_res[k][0][\"points\"]\n",
    "            else:\n",
    "                boxes = det_res[0][\"points\"]\n",
    "\n",
    "            # write predictions to images\n",
    "            draw_det_res(boxes, cv2.imread(img_name), img_name, vis_path)\n",
    "\n",
    "            boxes_len = len(boxes)\n",
    "            if boxes_len == 0:\n",
    "                print(\n",
    "                    f\"No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}\"\n",
    "                )\n",
    "                continue\n",
    "            else:\n",
    "                for box in boxes:\n",
    "                    box_list = box.tolist()\n",
    "\n",
    "                    current_res_dict = {\"points\": box_list}\n",
    "                    bbox_outputs.append(current_res_dict)\n",
    "\n",
    "            out_f.write(f\"{os.path.basename(img_name)}\\t{json.dumps(bbox_outputs)}\\n\")\n",
    "\n",
    "\n",
    "# Init recognition model of PaddleOCR\n",
    "def init_rec(config_path, ft_model_path=None):\n",
    "    config = load_config(config_path)\n",
    "    global_config = config[\"Global\"]\n",
    "    if ft_model_path != None:\n",
    "        global_config[\"pretrained_model\"] = ft_model_path\n",
    "\n",
    "    # build post process\n",
    "    post_process_class = build_post_process(config[\"PostProcess\"], global_config)\n",
    "\n",
    "    # build model\n",
    "    if hasattr(post_process_class, \"character\"):\n",
    "        char_num = len(getattr(post_process_class, \"character\"))\n",
    "        if config[\"Architecture\"][\"algorithm\"] in [\n",
    "            \"Distillation\",\n",
    "        ]:  # distillation model\n",
    "            for key in config[\"Architecture\"][\"Models\"]:\n",
    "                if (\n",
    "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\"name\"] == \"MultiHead\"\n",
    "                ):  # for multi head\n",
    "                    out_channels_list = {}\n",
    "                    if config[\"PostProcess\"][\"name\"] == \"DistillationSARLabelDecode\":\n",
    "                        char_num = char_num - 2\n",
    "                    out_channels_list[\"CTCLabelDecode\"] = char_num\n",
    "                    out_channels_list[\"SARLabelDecode\"] = char_num + 2\n",
    "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
    "                        \"out_channels_list\"\n",
    "                    ] = out_channels_list\n",
    "                else:\n",
    "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
    "                        \"out_channels\"\n",
    "                    ] = char_num\n",
    "        elif (\n",
    "            config[\"Architecture\"][\"Head\"][\"name\"] == \"MultiHead\"\n",
    "        ):  # for multi head loss\n",
    "            out_channels_list = {}\n",
    "            if config[\"PostProcess\"][\"name\"] == \"SARLabelDecode\":\n",
    "                char_num = char_num - 2\n",
    "            out_channels_list[\"CTCLabelDecode\"] = char_num\n",
    "            out_channels_list[\"SARLabelDecode\"] = char_num + 2\n",
    "            config[\"Architecture\"][\"Head\"][\"out_channels_list\"] = out_channels_list\n",
    "        else:  # base rec model\n",
    "            config[\"Architecture\"][\"Head\"][\"out_channels\"] = char_num\n",
    "\n",
    "    model = build_model(config[\"Architecture\"])\n",
    "\n",
    "    load_model(config, model)\n",
    "\n",
    "    # create data ops\n",
    "    transforms = []\n",
    "    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n",
    "        op_name = list(op)[0]\n",
    "        if \"Label\" in op_name:\n",
    "            continue\n",
    "        elif op_name in [\"RecResizeImg\"]:\n",
    "            op[op_name][\"infer_mode\"] = True\n",
    "        elif op_name == \"KeepKeys\":\n",
    "            if config[\"Architecture\"][\"algorithm\"] == \"SRN\":\n",
    "                op[op_name][\"keep_keys\"] = [\n",
    "                    \"image\",\n",
    "                    \"encoder_word_pos\",\n",
    "                    \"gsrm_word_pos\",\n",
    "                    \"gsrm_slf_attn_bias1\",\n",
    "                    \"gsrm_slf_attn_bias2\",\n",
    "                ]\n",
    "            elif config[\"Architecture\"][\"algorithm\"] == \"SAR\":\n",
    "                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\"]\n",
    "            elif config[\"Architecture\"][\"algorithm\"] == \"RobustScanner\":\n",
    "                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\", \"word_positons\"]\n",
    "            else:\n",
    "                op[op_name][\"keep_keys\"] = [\"image\"]\n",
    "        transforms.append(op)\n",
    "    global_config[\"infer_mode\"] = True\n",
    "    ops = create_operators(transforms, global_config)\n",
    "\n",
    "    model.eval()\n",
    "    return config, model, ops, post_process_class\n",
    "\n",
    "\n",
    "# Carry out text recognition using PaddleOCR\n",
    "def rec_ppocr(out_path, reg_yml, img_path, out_txt_name, ft_model_path=None):\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    # Paddle OCR Configs\n",
    "    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, ft_model_path)\n",
    "\n",
    "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
    "\n",
    "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
    "        for idx, img_name in enumerate(tqdm(images)):\n",
    "            with open(img_name, \"rb\") as f:\n",
    "                img = f.read()\n",
    "                data = {\"image\": img}\n",
    "            batch = transform(data, recOPS)\n",
    "            images = np.expand_dims(batch[0], axis=0)\n",
    "            images = paddle.to_tensor(images)\n",
    "            preds = recModel(images)\n",
    "\n",
    "            rec_res = recPost(preds)\n",
    "            formatted_res = rec_res[0][0].replace(\" \", \"\")\n",
    "            out_f.write(f\"{os.path.basename(img_name)}\\t{formatted_res}\\n\")\n",
    "\n",
    "\n",
    "# Chaining text detection and recognition end-to-end using PaddleOCR\n",
    "def spot_ppocr(\n",
    "    tmp_folder_path,\n",
    "    out_path,\n",
    "    det_yml,\n",
    "    reg_yml,\n",
    "    img_path,\n",
    "    out_txt_name,\n",
    "    det_ft_model_path=None,\n",
    "    rec_ft_model_path=None,\n",
    "):\n",
    "    if os.path.isdir(tmp_folder_path):\n",
    "        shutil.rmtree(tmp_folder_path)\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    # Paddle OCR Configs\n",
    "    detConfig, detModel, detOPS, detPost = init_det(det_yml, det_ft_model_path)\n",
    "    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, rec_ft_model_path)\n",
    "\n",
    "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
    "\n",
    "    output_dict = defaultdict(list)\n",
    "\n",
    "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
    "        for idx, img_name in enumerate(tqdm(images)):\n",
    "            img_id = os.path.basename(img_name)\n",
    "\n",
    "            # -------------------------------- STAGE I DETECTION ------------------------------\n",
    "            with open(img_name, \"rb\") as f:\n",
    "                img = f.read()\n",
    "                data = {\"image\": img}\n",
    "\n",
    "            batch = transform(data, detOPS)\n",
    "            images = np.expand_dims(batch[0], axis=0)\n",
    "            shape_list = np.expand_dims(batch[1], axis=0)\n",
    "            images = paddle.to_tensor(images)\n",
    "\n",
    "            # forward & post process\n",
    "            preds = detModel(images)\n",
    "            det_res = detPost(preds, shape_list)\n",
    "\n",
    "            # parser boxes if post_result is dict\n",
    "            if isinstance(det_res, dict):\n",
    "                for k in det_res.keys():\n",
    "                    boxes = det_res[k][0][\"points\"]\n",
    "            else:\n",
    "                boxes = det_res[0][\"points\"]\n",
    "\n",
    "            # Crop to patches\n",
    "            ori_img = cv2.imread(img_name)\n",
    "            h, w, c = ori_img.shape\n",
    "            if not os.path.exists(tmp_folder_path):\n",
    "                os.mkdir(tmp_folder_path)\n",
    "\n",
    "            for i, box in enumerate(boxes):\n",
    "                pt = box.tolist()\n",
    "                try:\n",
    "                    xs = [x[0] for x in pt]\n",
    "                    xs = np.clip(np.array(xs), a_min=0, a_max=w).tolist()\n",
    "                    ys = [x[1] for x in pt]\n",
    "                    ys = np.clip(np.array(ys), a_min=0, a_max=h).tolist()\n",
    "                    minx = min(xs)\n",
    "                    miny = min(ys)\n",
    "                    maxx = max(xs)\n",
    "                    maxy = max(ys)\n",
    "\n",
    "                    if (maxx - minx) <= 0 or (maxy - miny) <= 0:\n",
    "                        print(\n",
    "                            \"BBOX error occured when cropping image\"\n",
    "                            f\" {os.path.basename(img_name)} of {i}-th box\"\n",
    "                        )\n",
    "                        print(f\"Processed BBOX {minx} {miny} {maxx} {maxy}\")\n",
    "                        print(f\"Ori BBOX {pt}\")\n",
    "                        continue\n",
    "\n",
    "                    crop = ori_img[miny:maxy, minx:maxx]\n",
    "                    tmp_img_name = os.path.join(\n",
    "                        \"{}/{}_{}.jpg\".format(\n",
    "                            tmp_folder_path,\n",
    "                            img_name.split(\"/\")[-1].split(\".\")[0],\n",
    "                            str(i),\n",
    "                        )\n",
    "                    )\n",
    "                    cv2.imwrite(tmp_img_name, crop)\n",
    "                except Exception as e:\n",
    "                    print(\n",
    "                        f\"Error {e} occured when cropping image\"\n",
    "                        f\" {os.path.basename(img_name)} of {i}-th box\"\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "            boxes_len = len(boxes)\n",
    "            tmp_folder_len = len(os.listdir(tmp_folder_path))\n",
    "            if boxes_len == 0 or tmp_folder_len == 0:\n",
    "                print(\n",
    "                    f\"No output for {os.path.basename(img_name)}, bbox_len:\"\n",
    "                    f\" {boxes_len}, tmp_len: {tmp_folder_len}\"\n",
    "                )\n",
    "                shutil.rmtree(tmp_folder_path)\n",
    "                continue\n",
    "\n",
    "            if boxes_len != tmp_folder_len:\n",
    "                print(\n",
    "                    f\"mismatch bbox_len {boxes_len} and tmp_len {tmp_folder_len} for\"\n",
    "                    f\" image {os.path.basename(img_name)}\"\n",
    "                )\n",
    "                shutil.rmtree(tmp_folder_path)\n",
    "                continue\n",
    "\n",
    "            # ------------------------- Stage II Recognition ------------------------------\n",
    "            for file in get_image_file_list(tmp_folder_path):\n",
    "                with open(file, \"rb\") as f:\n",
    "                    img = f.read()\n",
    "                    data = {\"image\": img}\n",
    "                batch = transform(data, recOPS)\n",
    "                images = np.expand_dims(batch[0], axis=0)\n",
    "                images = paddle.to_tensor(images)\n",
    "                preds = recModel(images)\n",
    "\n",
    "                rec_res = recPost(preds)\n",
    "                formatted_res = rec_res[0][0].replace(\" \", \"\")\n",
    "\n",
    "                b_id = int(file.split(\"_\")[-1].replace(\".jpg\", \"\"))\n",
    "                crt_box = boxes[b_id]\n",
    "\n",
    "                output_dict[img_id].append(\n",
    "                    {\n",
    "                        \"points\": crt_box.tolist(),\n",
    "                        \"transcription\": formatted_res,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            shutil.rmtree(tmp_folder_path)\n",
    "\n",
    "            out_f.write(f\"{img_id}\\t{json.dumps(output_dict[img_id])}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qkVCWdZvPxq9"
   },
   "source": [
    "## Text Detection Using Pre-trained EAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1683728388847,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "_lNzSFjrRwaR",
    "outputId": "89d5e860-98b1-4db4-8b09-aa5389114f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n",
      "applications  doc\t   paddleocr.py  README_ch.md\t   StyleText\n",
      "benchmark     __init__.py  ppocr\t README.md\t   test_tipc\n",
      "configs       LICENSE\t   PPOCRLabel\t requirements.txt  tools\n",
      "deploy\t      MANIFEST.in  ppstructure\t setup.py\t   train.sh\n"
     ]
    }
   ],
   "source": [
    "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_dygraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39644,
     "status": "ok",
     "timestamp": 1683728428486,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "nRhS2KSZcheZ",
    "outputId": "d599c78b-2180-45ee-a71d-7404de6aaf6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:19:51] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:35<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_output\"\n",
    ")\n",
    "vis_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_output/vis\"\n",
    ")\n",
    "det_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
    "out_txt_name = \"east_output\"\n",
    "\n",
    "det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2tV2TdaUli2F"
   },
   "source": [
    "## Text Detection Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1683728428486,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "lpDrLo97nYaE",
    "outputId": "4a7525d3-c271-48ca-fbcc-1ed2defa3cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Overall Metric---\n",
      "Precision: 0.06, Recall: 0.25, HMean: 0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the HMean for them\n",
    "eval_config = {\n",
    "    \"IOU_CONSTRAINT\": 0.5,\n",
    "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
    "    \"WORD_SPOTTING\": False,\n",
    "}\n",
    "\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_output/east_output.txt\"\n",
    ")\n",
    "resDict = det_eval(gt_path, det_path, eval_config)\n",
    "precision, recall, hmean = (\n",
    "    resDict[\"method\"][\"precision\"],\n",
    "    resDict[\"method\"][\"recall\"],\n",
    "    resDict[\"method\"][\"hmean\"],\n",
    ")\n",
    "\n",
    "print(\"---Overall Metric---\")\n",
    "print(\n",
    "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
    "    f\" {round(hmean, 2)}\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gwzLm-WC0pMi"
   },
   "source": [
    "## Text Recognition Using Pre-trained CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1985,
     "status": "ok",
     "timestamp": 1683728430460,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "fBIKUCHn0uOe",
    "outputId": "0bc749d8-a950-456a-ad61-4cf5aa96fb4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:20:28] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n",
      "[2023/05/10 14:20:28] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n",
      "[2023/05/10 14:20:28] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 16.10it/s]\n"
     ]
    }
   ],
   "source": [
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/crnn_output\"\n",
    ")\n",
    "reg_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n",
    "out_txt_name = \"crnn_output\"\n",
    "\n",
    "rec_ppocr(out_path, reg_yml, img_path, out_txt_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AzXgaEma79ob"
   },
   "source": [
    "## Text Recognition Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1683728439198,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "mRYFc5Bi5cMP",
    "outputId": "791cb25c-99f5-46bc-c94e-25e80f5cdf8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correctly Recognized Words: 0.0\n",
      "Total Correctly Recognized Words (Case Insensitive): 0.0\n",
      "Total Edit Distance: 353\n",
      "Total Edit Distance (Case Insensitive): 349\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the Accuracy for them\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/crnn_output/crnn_output.txt\"\n",
    ")\n",
    "gt, pred = data_prep_rec_eval(gt_path, det_path)\n",
    "total_crw, total_crw_ci = total_accuracy(gt, pred)\n",
    "total_edit, total_edit_ci = total_edit_distance(gt, pred)\n",
    "\n",
    "print(f\"Total Correctly Recognized Words: {total_crw}\")\n",
    "print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n",
    "print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n",
    "print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n",
    "print(f\"Total Edit Distance: {total_edit}\")\n",
    "print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "8xtpP0rz-_CO"
   },
   "source": [
    "## Text Spotting Using Pre-trained EAST + CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_dygraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39894,
     "status": "ok",
     "timestamp": 1683728479080,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "DEkm-Rkh--DK",
    "outputId": "e57833f3-6a00-41cb-dd42-c1e7afd0e5bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:20:39] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n",
      "[2023/05/10 14:20:39] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n",
      "[2023/05/10 14:20:39] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n",
      "[2023/05/10 14:20:39] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:39<00:00,  1.96s/it]\n"
     ]
    }
   ],
   "source": [
    "tmp_folder_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_crnn_output/tmp\"\n",
    ")\n",
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_crnn_output\"\n",
    ")\n",
    "det_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",
    ")\n",
    "reg_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
    "out_txt_name = \"east_crnn_output\"\n",
    "\n",
    "spot_ppocr(tmp_folder_path, out_path, det_yml, reg_yml, img_path, out_txt_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T4xQ7K2t9z9I"
   },
   "source": [
    "## Text Spotting Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1683729342275,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "FUrvo2rT915O",
    "outputId": "cc3f7a8c-3d56-482f-c99f-28d2ea3224e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Overall Metric---\n",
      "Precision: 0.0, Recall: 0.0, HMean: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the HMean for them\n",
    "eval_config = {\n",
    "    \"IOU_CONSTRAINT\": 0.5,\n",
    "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
    "    \"WORD_SPOTTING\": True,\n",
    "}\n",
    "\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/pretrained_results/east_crnn_output/east_crnn_output.txt\"\n",
    ")\n",
    "resDict = det_eval(gt_path, det_path, eval_config)\n",
    "precision, recall, hmean = (\n",
    "    resDict[\"method\"][\"precision\"],\n",
    "    resDict[\"method\"][\"recall\"],\n",
    "    resDict[\"method\"][\"hmean\"],\n",
    ")\n",
    "\n",
    "print(\"---Overall Metric---\")\n",
    "print(\n",
    "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
    "    f\" {round(hmean, 2)}\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "YK9u3dJ3FmKL"
   },
   "source": [
    "## Fine-tuning EAST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1683728479870,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "7r65AU7aFp-B"
   },
   "outputs": [],
   "source": [
    "# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n",
    "# Please set Global.use_gpu=True if you are running on a machine with GPU\n",
    "# Fine-tuning for 100 epochs took 4 mins 29 secs on V100\n",
    "\n",
    "# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\" \\\n",
    "# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\" Global.use_gpu=False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "xUlpKV9-y-lM"
   },
   "source": [
    "## Fine-tuning CRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1683728479871,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "AUqMuLg8I17_"
   },
   "outputs": [],
   "source": [
    "# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n",
    "# Please set Global.use_gpu=True if you are running on a machine with GPU\n",
    "# Fine-tuning for 200 epochs took 5 mins 47 secs on V100\n",
    "\n",
    "# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\" \\\n",
    "# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\" Global.use_gpu=False\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2jhnx3NmzDwX"
   },
   "source": [
    "## Evaluate Fine-tuned EAST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1683728983962,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "y_dxujK16_sZ"
   },
   "outputs": [],
   "source": [
    "reset_dygraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28986,
     "status": "ok",
     "timestamp": 1683729013944,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "ezu45JVlzLp6",
    "outputId": "1d1c1ad5-db5e-42a4-e2f0-e3b24b6716e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:29:47] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:25<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_output\"\n",
    ")\n",
    "vis_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_output/vis\"\n",
    ")\n",
    "det_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
    "out_txt_name = \"east_output\"\n",
    "ft_model_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",
    ")\n",
    "\n",
    "det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name, ft_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1683729025372,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "lXH2SiLu2Dq7",
    "outputId": "78ad0009-578d-414b-e748-e61e64f66f6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Overall Metric---\n",
      "Precision: 0.91, Recall: 1.0, HMean: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the HMean for them\n",
    "eval_config = {\n",
    "    \"IOU_CONSTRAINT\": 0.5,\n",
    "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
    "    \"WORD_SPOTTING\": False,\n",
    "}\n",
    "\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_output/east_output.txt\"\n",
    ")\n",
    "resDict = det_eval(gt_path, det_path, eval_config)\n",
    "precision, recall, hmean = (\n",
    "    resDict[\"method\"][\"precision\"],\n",
    "    resDict[\"method\"][\"recall\"],\n",
    "    resDict[\"method\"][\"hmean\"],\n",
    ")\n",
    "\n",
    "print(\"---Overall Metric---\")\n",
    "print(\n",
    "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
    "    f\" {round(hmean, 2)}\\n\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-zVcdOzHzHI-"
   },
   "source": [
    "## Evaluate Fine-tuned CRNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2100,
     "status": "ok",
     "timestamp": 1683728513027,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "KFFf-JGQzIbk",
    "outputId": "3bce62e0-11bc-49a8-d238-166bd9dde0f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:21:52] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 33.35it/s]\n"
     ]
    }
   ],
   "source": [
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/crnn_output\"\n",
    ")\n",
    "reg_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n",
    "out_txt_name = \"crnn_output\"\n",
    "ft_model_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",
    ")\n",
    "\n",
    "rec_ppocr(out_path, reg_yml, img_path, out_txt_name, ft_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1683728517544,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "DBEByfMx2IBk",
    "outputId": "abb721ac-bdb2-4903-8f6b-e64226e04863"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Correctly Recognized Words: 0.8\n",
      "Total Correctly Recognized Words (Case Insensitive): 0.8\n",
      "Total Edit Distance: 8\n",
      "Total Edit Distance (Case Insensitive): 8\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the Accuracy for them\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/crnn_output/crnn_output.txt\"\n",
    ")\n",
    "gt, pred = data_prep_rec_eval(gt_path, det_path)\n",
    "total_crw, total_crw_ci = total_accuracy(gt, pred)\n",
    "total_edit, total_edit_ci = total_edit_distance(gt, pred)\n",
    "\n",
    "print(f\"Total Correctly Recognized Words: {total_crw}\")\n",
    "print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n",
    "print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n",
    "print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n",
    "print(f\"Total Edit Distance: {total_edit}\")\n",
    "print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ttAzKBbBEh2V"
   },
   "source": [
    "## Evaluate Fine-tuned EAST + CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 414,
     "status": "ok",
     "timestamp": 1683729256429,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "vTau0TqGCkGT"
   },
   "outputs": [],
   "source": [
    "reset_dygraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28431,
     "status": "ok",
     "timestamp": 1683729286756,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "dNfIEJ5yErX8",
    "outputId": "5e259654-ef70-4948-9ca9-647af2276934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023/05/10 14:34:18] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n",
      "[2023/05/10 14:34:18] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:27<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "tmp_folder_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_crnn_output/tmp\"\n",
    ")\n",
    "out_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_crnn_output\"\n",
    ")\n",
    "det_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",
    ")\n",
    "reg_yml = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",
    ")\n",
    "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
    "out_txt_name = \"east_crnn_output\"\n",
    "det_ft_model_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",
    ")\n",
    "rec_ft_model_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",
    ")\n",
    "\n",
    "spot_ppocr(\n",
    "    tmp_folder_path,\n",
    "    out_path,\n",
    "    det_yml,\n",
    "    reg_yml,\n",
    "    img_path,\n",
    "    out_txt_name,\n",
    "    det_ft_model_path,\n",
    "    rec_ft_model_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1683729334382,
     "user": {
      "displayName": "Chun Chet Ng",
      "userId": "03243561045656893985"
     },
     "user_tz": -480
    },
    "id": "rqXZOeC7Eyko",
    "outputId": "94ab9ff9-0548-4e73-f195-3d28c4d62ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Overall Metric---\n",
      "Precision: 0.45, Recall: 0.5, HMean: 0.48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's evaluate the HMean for them\n",
    "eval_config = {\n",
    "    \"IOU_CONSTRAINT\": 0.5,\n",
    "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
    "    \"WORD_SPOTTING\": True,\n",
    "}\n",
    "\n",
    "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
    "det_path = (\n",
    "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\" \\\n",
    "    \"License_Plate_Recognition/finetuned_results/east_crnn_output/east_crnn_output.txt\"\n",
    ")\n",
    "resDict = det_eval(gt_path, det_path, eval_config)\n",
    "precision, recall, hmean = (\n",
    "    resDict[\"method\"][\"precision\"],\n",
    "    resDict[\"method\"][\"recall\"],\n",
    "    resDict[\"method\"][\"hmean\"],\n",
    ")\n",
    "\n",
    "print(\"---Overall Metric---\")\n",
    "print(\n",
    "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
    "    f\" {round(hmean, 2)}\\n\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPWvc8QDtGzaIGyWybgpxzN",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
