{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4g-xUrfITPUL"
      },
      "source": [
        "# 5. Text Detection, Recognition & Spotting on the CCPD 2019 Dataset\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SMtCA2-mTPUO"
      },
      "source": [
        "In this notebook, we will be learning how the carry out text detection, recognition and spotting on the [Chinese City Parking Dataset](https://github.com/detectRecog/CCPD) using [PPOCR](https://github.com/PaddlePaddle/PaddleOCR). We will first install and import necessary libraries, then we will define commonly used functions for creating models, inferencing image, and evaluating results. Lastly, other than evaluating the results of pre-trained models, we will look at the steps to perform fine-tuning and the respective results.\n",
        "\n",
        "**Table of Contents**\n",
        "\n",
        "1. [Mount Google Drive](#mount-google-drive)\n",
        "2. [Install PPOCR](#install-ppocr)\n",
        "3. [Define Commonly Used Functions](#define-commonly-used-functions)\n",
        "4. [Evaluate with Pre-trained Models](#evaluated-with-pre-trained-models)\n",
        "5. [Evaluate with Fine-tuned Models](#evaluate-with-fine-tuned-models)\n",
        "\n",
        "Get your seatbelt on and let's get started! 🔥⭐\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3i45jwHyzlSC"
      },
      "source": [
        "## Mount Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSrmdTXqvn9w",
        "outputId": "8f00c2fa-4a98-40ee-b9f9-41e8384b0140"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tLWyxVEyo1T",
        "outputId": "51020b74-cdd9-4a24-ee99-5e574e7b2309"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/CCPD2019\n",
            "CCPD2019.zip  train_crop     train.txt\tval_crop     val.txt\n",
            "train\t      train_rec.txt  val\tval_rec.txt\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive\"\n",
        "%cd \"CCPD2019\"\n",
        "!ls"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WGcFIpNrzw28"
      },
      "source": [
        "## Install PPOCR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zsD-t3CsK4zs",
        "outputId": "e39fd3c8-2c67-4240-dcd4-d0ac11153ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition\n",
            "fatal: destination path 'PaddleOCR' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.3)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.0)\n",
            "Collecting pyclipper (from -r requirements.txt (line 4))\n",
            "  Downloading pyclipper-1.3.0.post4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (813 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.9/813.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from -r requirements.txt (line 5))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n",
            "Collecting visualdl (from -r requirements.txt (line 8))\n",
            "  Downloading visualdl-2.5.2-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from -r requirements.txt (line 9))\n",
            "  Downloading rapidfuzz-3.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python==4.6.0.66 (from -r requirements.txt (line 10))\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-contrib-python==4.6.0.66 (from -r requirements.txt (line 11))\n",
            "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.29.34)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.9.2)\n",
            "Collecting premailer (from -r requirements.txt (line 14))\n",
            "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (3.0.10)\n",
            "Collecting attrdict (from -r requirements.txt (line 16))\n",
            "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
            "Collecting Polygon3 (from -r requirements.txt (line 17))\n",
            "  Downloading Polygon3-3.0.9.1.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting lanms-neo==1.0.2 (from -r requirements.txt (line 18))\n",
            "  Downloading lanms_neo-1.0.2.tar.gz (39 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting PyMuPDF<1.21.0 (from -r requirements.txt (line 19))\n",
            "  Downloading PyMuPDF-1.20.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (2023.4.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->-r requirements.txt (line 3)) (3.7.1)\n",
            "Collecting bce-python-sdk (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading bce_python_sdk-0.8.83-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flask>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.2.4)\n",
            "Collecting Flask-Babel>=3.0.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading flask_babel-3.1.0-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (2.27.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (1.5.3)\n",
            "Collecting x2paddle>=1.4.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading x2paddle-1.4.1-py3-none-any.whl (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paddle2onnx>=1.0.5 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading paddle2onnx-1.0.6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rarfile (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
            "Collecting gradio==3.11.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading gradio-3.11.0-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tritonclient[all] (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading tritonclient-2.33.0-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from visualdl->-r requirements.txt (line 8)) (5.9.5)\n",
            "Collecting onnx>=1.6.0 (from visualdl->-r requirements.txt (line 8))\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2023.4.0)\n",
            "Collecting h11<0.13,>=0.11 (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.2.0)\n",
            "Collecting orjson (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading orjson-3.8.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading paramiko-3.1.0-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodome (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading pycryptodome-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.10.7)\n",
            "Collecting pydub (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (6.0)\n",
            "Collecting uvicorn (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cssselect (from premailer->-r requirements.txt (line 14))\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting cssutils (from premailer->-r requirements.txt (line 14))\n",
            "  Downloading cssutils-2.6.0-py3-none-any.whl (399 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from premailer->-r requirements.txt (line 14)) (5.3.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->-r requirements.txt (line 15)) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (8.1.3)\n",
            "Requirement already satisfied: Babel>=2.12 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2.12.1)\n",
            "Requirement already satisfied: pytz>=2022.7 in /usr/local/lib/python3.10/dist-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2022.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.6.0->visualdl->-r requirements.txt (line 8)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.11.1)\n",
            "Requirement already satisfied: future>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from bce-python-sdk->visualdl->-r requirements.txt (line 8)) (0.18.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.4)\n",
            "Collecting python-rapidjson>=0.9.1 (from tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading python_rapidjson-1.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from tritonclient[all]->visualdl->-r requirements.txt (line 8)) (1.54.0)\n",
            "Collecting geventhttpclient<=2.0.2,>=1.4.4 (from tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading geventhttpclient-2.0.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting gevent>=0.13 (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading gevent-22.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m119.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading Brotli-1.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.1.2)\n",
            "Collecting starlette<0.27.0,>=0.26.1 (from fastapi->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins (from markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading mdit_py_plugins-0.3.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bcrypt>=3.2 (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (40.0.2)\n",
            "Collecting pynacl>=1.5 (from paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->x2paddle>=1.4.0->visualdl->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (1.15.1)\n",
            "Collecting zope.event (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Collecting zope.interface (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading zope.interface-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gevent>=0.13->geventhttpclient<=2.0.2,>=1.4.4->tritonclient[all]->visualdl->-r requirements.txt (line 8)) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of httpcore to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading httpcore-0.16.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading httpcore-0.16.2-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading httpcore-0.16.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.4/68.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (3.6.2)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]->gradio==3.11.0->visualdl->-r requirements.txt (line 8))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko->gradio==3.11.0->visualdl->-r requirements.txt (line 8)) (2.21)\n",
            "Building wheels for collected packages: lanms-neo, Polygon3, ffmpy\n",
            "  Building wheel for lanms-neo (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lanms-neo: filename=lanms_neo-1.0.2-cp310-cp310-linux_x86_64.whl size=115491 sha256=f00e77383a1dff5cee3b2c7d102b27f3cb8f4ab17a4edde9e976ca072b87f8d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/2d/97/6339a08bcd70b34137a13f6506b29cdfa20fd345d4781dbefc\n",
            "  Building wheel for Polygon3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Polygon3: filename=Polygon3-3.0.9.1-cp310-cp310-linux_x86_64.whl size=119435 sha256=0cfe3ce4b6a907f9eae38de336ce5dbfbf464eca23c5ae5f797fec3cc1a206d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/b7/f6/b4e24f56a1cc9856dca98cc2fdc3915d7649b39b62f3dbca9e\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=f928e569e7258107fa3b42766e02f184092f3a3c4f10b42934259a80d4d257de\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built lanms-neo Polygon3 ffmpy\n",
            "Installing collected packages: rarfile, pydub, pyclipper, Polygon3, paddle2onnx, lmdb, lanms-neo, ffmpy, brotli, zope.interface, zope.event, websockets, uc-micro-py, rapidfuzz, python-rapidjson, python-multipart, PyMuPDF, pycryptodome, orjson, opencv-python, opencv-contrib-python, onnx, multidict, h11, frozenlist, cssutils, cssselect, bcrypt, attrdict, async-timeout, yarl, x2paddle, uvicorn, tritonclient, starlette, pynacl, premailer, mdit-py-plugins, linkify-it-py, httpcore, gevent, bce-python-sdk, aiosignal, paramiko, httpx, geventhttpclient, Flask-Babel, fastapi, aiohttp, gradio, visualdl\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.7.0.72\n",
            "    Uninstalling opencv-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-python-4.7.0.72\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.7.0.72\n",
            "    Uninstalling opencv-contrib-python-4.7.0.72:\n",
            "      Successfully uninstalled opencv-contrib-python-4.7.0.72\n",
            "Successfully installed Flask-Babel-3.1.0 Polygon3-3.0.9.1 PyMuPDF-1.20.2 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrdict-2.0.1 bce-python-sdk-0.8.83 bcrypt-4.0.1 brotli-1.0.9 cssselect-1.2.0 cssutils-2.6.0 fastapi-0.95.1 ffmpy-0.3.0 frozenlist-1.3.3 gevent-22.10.2 geventhttpclient-2.0.2 gradio-3.11.0 h11-0.12.0 httpcore-0.15.0 httpx-0.24.0 lanms-neo-1.0.2 linkify-it-py-2.0.2 lmdb-1.4.1 mdit-py-plugins-0.3.5 multidict-6.0.4 onnx-1.14.0 opencv-contrib-python-4.6.0.66 opencv-python-4.6.0.66 orjson-3.8.12 paddle2onnx-1.0.6 paramiko-3.1.0 premailer-3.10.0 pyclipper-1.3.0.post4 pycryptodome-3.17 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.6 python-rapidjson-1.10 rapidfuzz-3.0.0 rarfile-4.0 starlette-0.26.1 tritonclient-2.33.0 uc-micro-py-1.0.2 uvicorn-0.22.0 visualdl-2.5.2 websockets-11.0.3 x2paddle-1.4.1 yarl-1.9.2 zope.event-4.6 zope.interface-6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting paddlepaddle\n",
            "  Downloading paddlepaddle-2.4.2-cp310-cp310-manylinux1_x86_64.whl (121.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.7/121.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.22.4)\n",
            "Collecting protobuf<=3.20.0,>=3.1.0 (from paddlepaddle)\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (8.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (1.16.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (4.4.2)\n",
            "Collecting astor (from paddlepaddle)\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting paddle-bfloat==0.1.7 (from paddlepaddle)\n",
            "  Downloading paddle_bfloat-0.1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (383 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum==3.3.0 in /usr/local/lib/python3.10/dist-packages (from paddlepaddle) (3.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->paddlepaddle) (3.4)\n",
            "Installing collected packages: paddle-bfloat, protobuf, astor, paddlepaddle\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-api-core 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.9.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.19.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.15.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.11.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.9.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "onnx 1.14.0 requires protobuf>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed astor-0.8.1 paddle-bfloat-0.1.7 paddlepaddle-2.4.2 protobuf-3.20.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting levenshtein\n",
            "  Downloading Levenshtein-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rapidfuzz<4.0.0,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from levenshtein) (3.0.0)\n",
            "Installing collected packages: levenshtein\n",
            "Successfully installed levenshtein-0.21.0\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/\"\n",
        "!git clone https://github.com/PaddlePaddle/PaddleOCR.git\n",
        "%cd ./PaddleOCR\n",
        "!pip install -r requirements.txt\n",
        "!pip install paddlepaddle\n",
        "!pip install levenshtein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dck-MuVWBH3F",
        "outputId": "cff21911-ab41-45f7-895a-f61ee4127a9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\n",
            "--2023-05-15 02:48:41--  https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n",
            "Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n",
            "Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33679360 (32M) [application/x-tar]\n",
            "Saving to: ‘det_mv3_east_v2.0_train.tar’\n",
            "\n",
            "det_mv3_east_v2.0_t 100%[===================>]  32.12M  9.21MB/s    in 16s     \n",
            "\n",
            "2023-05-15 02:48:59 (1.97 MB/s) - ‘det_mv3_east_v2.0_train.tar’ saved [33679360/33679360]\n",
            "\n",
            "det_mv3_east_v2.0_train/\n",
            "det_mv3_east_v2.0_train/best_accuracy.pdparams\n",
            "det_mv3_east_v2.0_train/best_accuracy.states\n",
            "det_mv3_east_v2.0_train/best_accuracy.pdopt\n",
            "det_mv3_east_v2.0_train/train.log\n",
            "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\n",
            "--2023-05-15 02:49:00--  https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n",
            "Resolving paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)... 103.235.46.61, 2409:8c04:1001:1002:0:ff:b001:368a\n",
            "Connecting to paddleocr.bj.bcebos.com (paddleocr.bj.bcebos.com)|103.235.46.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 51200000 (49M) [application/x-tar]\n",
            "Saving to: ‘rec_mv3_none_bilstm_ctc_v2.0_train.tar’\n",
            "\n",
            "rec_mv3_none_bilstm 100%[===================>]  48.83M  9.03MB/s    in 15s     \n",
            "\n",
            "2023-05-15 02:49:16 (3.17 MB/s) - ‘rec_mv3_none_bilstm_ctc_v2.0_train.tar’ saved [51200000/51200000]\n",
            "\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.pdopt\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/.DS_Store\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/train.log\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.pdparams\n",
            "rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy.states\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east\"\n",
        "!rm -rf *.tar*\n",
        "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/det_mv3_east_v2.0_train.tar\n",
        "!tar xvf det_mv3_east_v2.0_train.tar\n",
        "\n",
        "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn\"\n",
        "!rm -rf *.tar*\n",
        "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/en/rec_mv3_none_bilstm_ctc_v2.0_train.tar\n",
        "!tar xvf rec_mv3_none_bilstm_ctc_v2.0_train.tar\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jpDTGPnQM1fn"
      },
      "source": [
        "## Define Commonly Used Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS4hihgtQZMv",
        "outputId": "391ab190-fb88-4d75-8003-170d09d1f691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\n",
            "applications  doc\t   paddleocr.py  README_ch.md\t   StyleText\n",
            "benchmark     __init__.py  ppocr\t README.md\t   test_tipc\n",
            "configs       LICENSE\t   PPOCRLabel\t requirements.txt  tools\n",
            "deploy\t      MANIFEST.in  ppstructure\t setup.py\t   train.sh\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/PaddleOCR\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C5Zq81E1TPUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import sys\n",
        "import json\n",
        "import yaml\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import typing\n",
        "from typing import Dict, List, Optional\n",
        "\n",
        "import paddle\n",
        "from paddle import fluid\n",
        "from ppocr.data import create_operators, transform\n",
        "from ppocr.modeling.architectures import build_model\n",
        "from ppocr.postprocess import build_post_process\n",
        "from ppocr.utils.save_load import load_model\n",
        "from ppocr.utils.utility import get_image_file_list\n",
        "\n",
        "__dir__ = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/PaddleOCR\"\n",
        ")\n",
        "sys.path.append(__dir__)\n",
        "sys.path.append(os.path.abspath(os.path.join(__dir__, \"..\")))\n",
        "\n",
        "from det_eval import evaluation\n",
        "from collections import defaultdict\n",
        "from rec_eval import total_accuracy, total_edit_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZNjCzMaVTPUV"
      },
      "outputs": [],
      "source": [
        "def reset_dygraph():\n",
        "    \"\"\"Reset dygraph.\"\"\"\n",
        "    fluid.dygraph.disable_dygraph()\n",
        "    fluid.dygraph.enable_dygraph()\n",
        "\n",
        "\n",
        "def load_config(file_path: str):\n",
        "    \"\"\"Load PaddleOCR config (yml/yaml file).\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path of the config file.\n",
        "\n",
        "    Returns:\n",
        "        config (dict): Global config.\n",
        "    \"\"\"\n",
        "\n",
        "    _, ext = os.path.splitext(file_path)\n",
        "    assert ext in [\".yml\", \".yaml\"], \"only support yaml files for now\"\n",
        "    config = yaml.load(open(file_path, \"rb\"), Loader=yaml.Loader)\n",
        "    return config"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp99JzFCTPUV"
      },
      "source": [
        "### Functions Related to Text Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "shjT6yg-M1fn"
      },
      "outputs": [],
      "source": [
        "def det_eval(gt_path: str, det_path: str, eval_config: Dict):\n",
        "    \"\"\"Evaluate detection result from .txt files.\n",
        "\n",
        "    Args:\n",
        "        gt_path (str): Path to ground-truth annotation in .txt file.\n",
        "        det_path (str): Path to detection result in .txt file.\n",
        "        eval_config (Dict): Evaluation configuration.\n",
        "\n",
        "    Returns:\n",
        "        resDict (Dict): A dict storing overall and per-sample evaluation result.\n",
        "    \"\"\"\n",
        "    # Prepare GT\n",
        "    gt_dict = defaultdict(list)\n",
        "    with open(gt_path, mode=\"r\") as in_txt:\n",
        "        lines = in_txt.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            values = line.split(\"\\t\")\n",
        "            img_id = values[0]\n",
        "            annos = json.loads(values[1])\n",
        "\n",
        "            for anno in annos:\n",
        "                trans = anno[\"transcription\"]\n",
        "                bbox = anno[\"points\"]\n",
        "                xs = [x[0] for x in bbox]\n",
        "                ys = [x[1] for x in bbox]\n",
        "                xmin = min(xs)\n",
        "                xmax = max(xs)\n",
        "                ymin = min(ys)\n",
        "                ymax = max(ys)\n",
        "                gt_dict[img_id].append([xmin, ymin, xmax, ymax, trans])\n",
        "\n",
        "    # Prepare Det\n",
        "    det_dict = defaultdict(list)\n",
        "    with open(det_path, mode=\"r\") as in_txt:\n",
        "        lines = in_txt.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            values = line.split(\"\\t\")\n",
        "            img_id = values[0]\n",
        "            annos = json.loads(values[1])\n",
        "\n",
        "            for anno in annos:\n",
        "                bbox = anno[\"points\"]\n",
        "                xs = [x[0] for x in bbox]\n",
        "                ys = [x[1] for x in bbox]\n",
        "                xmin = min(xs)\n",
        "                xmax = max(xs)\n",
        "                ymin = min(ys)\n",
        "                ymax = max(ys)\n",
        "\n",
        "                width = xmax - xmin\n",
        "                height = ymax - ymin\n",
        "\n",
        "                pred_entry = [xmin, ymin, xmax, ymax]\n",
        "\n",
        "                if eval_config[\"WORD_SPOTTING\"]:\n",
        "                    trans = anno[\"transcription\"]\n",
        "                    pred_entry.append(trans)\n",
        "\n",
        "                det_dict[img_id].append(pred_entry)\n",
        "\n",
        "    resDict = evaluation(gt_dict, det_dict, eval_config)\n",
        "    return resDict\n",
        "\n",
        "\n",
        "def draw_det_res(dt_boxes: List[List], img: np.ndarray, img_name: str, save_path: str):\n",
        "    \"\"\"Draw detection result from PaddleOCR.\n",
        "\n",
        "    Args:\n",
        "        dt_boxes (List[List]): List of boxes to be drawn on image.\n",
        "        img (np.ndarray): Image to be drawn with dt_boxes.\n",
        "        img_name (str): Output file name.\n",
        "        save_path (str): Path to output folder.\n",
        "    \"\"\"\n",
        "    if len(dt_boxes) > 0:\n",
        "        src_im = img\n",
        "        for box in dt_boxes:\n",
        "            box = np.array(box).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(src_im, [box], True, color=(255, 255, 0), thickness=2)\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        save_path = os.path.join(save_path, os.path.basename(img_name))\n",
        "        cv2.imwrite(save_path, src_im)\n",
        "\n",
        "\n",
        "def init_det(config_path: str, ft_model_path: Optional[str] = None):\n",
        "    \"\"\"Initialise detection model of PaddleOCR.\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to config.\n",
        "        ft_model_path (Optional[str], optional): Path to pre-trained model. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        config (dict): Config.\n",
        "        model (torch.nn.Module): Detection model built from config.\n",
        "        ops (List): List of pre-processing operation.\n",
        "        post_process_class (typing.Any): Object for post-processing.\n",
        "    \"\"\"\n",
        "    config = load_config(config_path)\n",
        "    global_config = config[\"Global\"]\n",
        "    if ft_model_path != None:\n",
        "        global_config[\"pretrained_model\"] = ft_model_path\n",
        "\n",
        "    # build model\n",
        "    model = build_model(config[\"Architecture\"])\n",
        "\n",
        "    load_model(config, model)\n",
        "    # build post process\n",
        "    post_process_class = build_post_process(config[\"PostProcess\"])\n",
        "\n",
        "    # create data ops\n",
        "    transforms = []\n",
        "    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n",
        "        op_name = list(op)[0]\n",
        "        if \"Label\" in op_name:\n",
        "            continue\n",
        "        elif op_name == \"KeepKeys\":\n",
        "            op[op_name][\"keep_keys\"] = [\"image\", \"shape\"]\n",
        "        transforms.append(op)\n",
        "\n",
        "    ops = create_operators(transforms, global_config)\n",
        "\n",
        "    model.eval()\n",
        "    return config, model, ops, post_process_class\n",
        "\n",
        "\n",
        "def det_ppocr(\n",
        "    out_path: str,\n",
        "    vis_path: str,\n",
        "    det_yml: str,\n",
        "    img_path: str,\n",
        "    out_txt_name: str,\n",
        "    ft_model_path: Optional[str] = None,\n",
        "):\n",
        "    \"\"\"Carry out text detection using PaddleOCR.\n",
        "\n",
        "    Args:\n",
        "        out_path (str): Path to save detection result.\n",
        "        vis_path (str): Path to save result visualization.\n",
        "        det_yml (str): Path to detection config file (yml/yaml).\n",
        "        img_path (str): Path to image for text detection.\n",
        "        out_txt_name (str): File name to save detection output.\n",
        "        ft_model_path (Optional[str], optional): Path to pre-trained model. Defaults to None.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    if not os.path.exists(vis_path):\n",
        "        os.makedirs(vis_path)\n",
        "\n",
        "    # Paddle OCR Configs\n",
        "    detConfig, detModel, detOPS, detPost = init_det(det_yml, ft_model_path)\n",
        "\n",
        "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
        "\n",
        "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
        "        for idx, img_name in enumerate(tqdm(images)):\n",
        "            bbox_outputs = []\n",
        "            with open(img_name, \"rb\") as f:\n",
        "                img = f.read()\n",
        "                data = {\"image\": img}\n",
        "\n",
        "            batch = transform(data, detOPS)\n",
        "            images = np.expand_dims(batch[0], axis=0)\n",
        "            shape_list = np.expand_dims(batch[1], axis=0)\n",
        "            images = paddle.to_tensor(images)\n",
        "\n",
        "            # forward & post process\n",
        "            preds = detModel(images)\n",
        "            det_res = detPost(preds, shape_list)\n",
        "\n",
        "            # parser boxes if post_result is dict\n",
        "            if isinstance(det_res, dict):\n",
        "                for k in det_res.keys():\n",
        "                    boxes = det_res[k][0][\"points\"]\n",
        "            else:\n",
        "                boxes = det_res[0][\"points\"]\n",
        "\n",
        "            # write predictions to images\n",
        "            draw_det_res(boxes, cv2.imread(img_name), img_name, vis_path)\n",
        "\n",
        "            boxes_len = len(boxes)\n",
        "            if boxes_len == 0:\n",
        "                print(\n",
        "                    f\"No output for {os.path.basename(img_name)}, bbox_len: {boxes_len}\"\n",
        "                )\n",
        "                continue\n",
        "            else:\n",
        "                for box in boxes:\n",
        "                    box_list = box.tolist()\n",
        "\n",
        "                    current_res_dict = {\"points\": box_list}\n",
        "                    bbox_outputs.append(current_res_dict)\n",
        "\n",
        "            out_f.write(f\"{os.path.basename(img_name)}\\t{json.dumps(bbox_outputs)}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tY1gULsrTPUW"
      },
      "source": [
        "### Functions Related to Text Recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vyIHB8pZTPUX"
      },
      "outputs": [],
      "source": [
        "def data_prep_rec_eval(gt_path: str, rec_path: str):\n",
        "    \"\"\"Prepare ground-truth and prediction lists from .txt files for\n",
        "    computing accuracy and edit distance for text recognition.\n",
        "\n",
        "    Args:\n",
        "        gt_path (str): Path to ground-truth annotation in .txt file.\n",
        "        rec_path (str): Path to recognition result in .txt file.\n",
        "\n",
        "    Returns:\n",
        "        gt (list): List of texts from ground-truth annotation files.\n",
        "        pred (list): List of texts from prediction.\n",
        "    \"\"\"\n",
        "    # Prepare GT\n",
        "    gt_dict = {}\n",
        "    with open(gt_path, mode=\"r\") as in_txt:\n",
        "        lines = in_txt.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            values = line.split(\"\\t\")\n",
        "            img_id = values[0]\n",
        "            gt_dict[img_id] = values[1]\n",
        "\n",
        "    # Prepare Det\n",
        "    det_dict = {}\n",
        "    with open(rec_path, mode=\"r\") as in_txt:\n",
        "        lines = in_txt.readlines()\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            values = line.split(\"\\t\")\n",
        "            img_id = values[0]\n",
        "            det_dict[img_id] = values[1]\n",
        "\n",
        "    gt = []\n",
        "    pred = []\n",
        "\n",
        "    for key, val in gt_dict.items():\n",
        "        if key in det_dict.keys():\n",
        "            gt.append(val)\n",
        "            pred.append(det_dict[key])\n",
        "\n",
        "    return gt, pred\n",
        "\n",
        "\n",
        "def init_rec(config_path: str, ft_model_path: Optional[str] = None):\n",
        "    \"\"\"Initialise recognition model of PaddleOCR\n",
        "\n",
        "    Args:\n",
        "        config_path (str): Path to config\n",
        "        ft_model_path (Optional[str], optional): Path to pre-trained model. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        config (dict): Config\n",
        "        model (torch.nn.Module): Recognition model built from config\n",
        "        ops (List): List of pre-processing operation\n",
        "        post_process_class (typing.Any): Object for post-processing\n",
        "    \"\"\"\n",
        "    config = load_config(config_path)\n",
        "    global_config = config[\"Global\"]\n",
        "    if ft_model_path != None:\n",
        "        global_config[\"pretrained_model\"] = ft_model_path\n",
        "\n",
        "    # build post process\n",
        "    post_process_class = build_post_process(config[\"PostProcess\"], global_config)\n",
        "\n",
        "    # build model\n",
        "    if hasattr(post_process_class, \"character\"):\n",
        "        char_num = len(getattr(post_process_class, \"character\"))\n",
        "        if config[\"Architecture\"][\"algorithm\"] in [\n",
        "            \"Distillation\",\n",
        "        ]:  # distillation model\n",
        "            for key in config[\"Architecture\"][\"Models\"]:\n",
        "                if (\n",
        "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\"name\"] == \"MultiHead\"\n",
        "                ):  # for multi head\n",
        "                    out_channels_list = {}\n",
        "                    if config[\"PostProcess\"][\"name\"] == \"DistillationSARLabelDecode\":\n",
        "                        char_num = char_num - 2\n",
        "                    out_channels_list[\"CTCLabelDecode\"] = char_num\n",
        "                    out_channels_list[\"SARLabelDecode\"] = char_num + 2\n",
        "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
        "                        \"out_channels_list\"\n",
        "                    ] = out_channels_list\n",
        "                else:\n",
        "                    config[\"Architecture\"][\"Models\"][key][\"Head\"][\n",
        "                        \"out_channels\"\n",
        "                    ] = char_num\n",
        "        elif (\n",
        "            config[\"Architecture\"][\"Head\"][\"name\"] == \"MultiHead\"\n",
        "        ):  # for multi head loss\n",
        "            out_channels_list = {}\n",
        "            if config[\"PostProcess\"][\"name\"] == \"SARLabelDecode\":\n",
        "                char_num = char_num - 2\n",
        "            out_channels_list[\"CTCLabelDecode\"] = char_num\n",
        "            out_channels_list[\"SARLabelDecode\"] = char_num + 2\n",
        "            config[\"Architecture\"][\"Head\"][\"out_channels_list\"] = out_channels_list\n",
        "        else:  # base rec model\n",
        "            config[\"Architecture\"][\"Head\"][\"out_channels\"] = char_num\n",
        "\n",
        "    model = build_model(config[\"Architecture\"])\n",
        "\n",
        "    load_model(config, model)\n",
        "\n",
        "    # create data ops\n",
        "    transforms = []\n",
        "    for op in config[\"Eval\"][\"dataset\"][\"transforms\"]:\n",
        "        op_name = list(op)[0]\n",
        "        if \"Label\" in op_name:\n",
        "            continue\n",
        "        elif op_name in [\"RecResizeImg\"]:\n",
        "            op[op_name][\"infer_mode\"] = True\n",
        "        elif op_name == \"KeepKeys\":\n",
        "            if config[\"Architecture\"][\"algorithm\"] == \"SRN\":\n",
        "                op[op_name][\"keep_keys\"] = [\n",
        "                    \"image\",\n",
        "                    \"encoder_word_pos\",\n",
        "                    \"gsrm_word_pos\",\n",
        "                    \"gsrm_slf_attn_bias1\",\n",
        "                    \"gsrm_slf_attn_bias2\",\n",
        "                ]\n",
        "            elif config[\"Architecture\"][\"algorithm\"] == \"SAR\":\n",
        "                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\"]\n",
        "            elif config[\"Architecture\"][\"algorithm\"] == \"RobustScanner\":\n",
        "                op[op_name][\"keep_keys\"] = [\"image\", \"valid_ratio\", \"word_positons\"]\n",
        "            else:\n",
        "                op[op_name][\"keep_keys\"] = [\"image\"]\n",
        "        transforms.append(op)\n",
        "    global_config[\"infer_mode\"] = True\n",
        "    ops = create_operators(transforms, global_config)\n",
        "\n",
        "    model.eval()\n",
        "    return config, model, ops, post_process_class\n",
        "\n",
        "\n",
        "def rec_ppocr(\n",
        "    out_path: str,\n",
        "    reg_yml: str,\n",
        "    img_path: str,\n",
        "    out_txt_name: str,\n",
        "    ft_model_path: Optional[str] = None,\n",
        "):\n",
        "    \"\"\"Carry out text recognition using PaddleOCR\n",
        "\n",
        "    Args:\n",
        "        out_path (str): Path to save recognition result\n",
        "        reg_yml (str): Path to recognition config file (yml/yaml)\n",
        "        img_path (str): Path to image for text recognition\n",
        "        out_txt_name (str): File name to save recognition output\n",
        "        ft_model_path (Optional[str], optional): Path to pre-trained model. Defaults to None.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    # Paddle OCR Configs\n",
        "    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, ft_model_path)\n",
        "\n",
        "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
        "\n",
        "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
        "        for idx, img_name in enumerate(tqdm(images)):\n",
        "            with open(img_name, \"rb\") as f:\n",
        "                img = f.read()\n",
        "                data = {\"image\": img}\n",
        "            batch = transform(data, recOPS)\n",
        "            images = np.expand_dims(batch[0], axis=0)\n",
        "            images = paddle.to_tensor(images)\n",
        "            preds = recModel(images)\n",
        "\n",
        "            rec_res = recPost(preds)\n",
        "            formatted_res = rec_res[0][0].replace(\" \", \"\")\n",
        "            out_f.write(f\"{os.path.basename(img_name)}\\t{formatted_res}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8KT6i9LQTPUX"
      },
      "source": [
        "### Functions Related to Text Spotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZTGd9naCTPUY"
      },
      "outputs": [],
      "source": [
        "def spot_ppocr(\n",
        "    tmp_folder_path: str,\n",
        "    out_path: str,\n",
        "    det_yml: str,\n",
        "    reg_yml: str,\n",
        "    img_path: str,\n",
        "    out_txt_name: str,\n",
        "    det_ft_model_path: Optional[str] = None,\n",
        "    rec_ft_model_path: Optional[str] = None,\n",
        "):\n",
        "    \"\"\"Chaining text detection and recognition end-to-end using PaddleOCR.\n",
        "\n",
        "    Args:\n",
        "        tmp_folder_path (str): Temporary folder path to store intermediate output.\n",
        "        out_path (str): Path to save text spotting result\n",
        "        det_yml (str): Path to detection config file (yml/yaml)\n",
        "        reg_yml (str): Path to recognition config file (yml/yaml)\n",
        "        img_path (str): Path to image for text spotting\n",
        "        out_txt_name (str): File name to save detection output\n",
        "        det_ft_model_path (Optional[str], optional): Path to text detection pre-trained model. Defaults to None.\n",
        "        rec_ft_model_path (Optional[str], optional): Path to text recognition pre-trained model. Defaults to None.\n",
        "    \"\"\"\n",
        "    if os.path.isdir(tmp_folder_path):\n",
        "        shutil.rmtree(tmp_folder_path)\n",
        "\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    # Paddle OCR Configs\n",
        "    detConfig, detModel, detOPS, detPost = init_det(det_yml, det_ft_model_path)\n",
        "    recConfig, recModel, recOPS, recPost = init_rec(reg_yml, rec_ft_model_path)\n",
        "\n",
        "    images = glob.glob(os.path.join(img_path, \"*\"))  # load images\n",
        "\n",
        "    output_dict = defaultdict(list)\n",
        "\n",
        "    with open(os.path.join(out_path, f\"{out_txt_name}.txt\"), mode=\"w\") as out_f:\n",
        "        for idx, img_name in enumerate(tqdm(images)):\n",
        "            img_id = os.path.basename(img_name)\n",
        "\n",
        "            # -------------------------------- STAGE I DETECTION ------------------------------\n",
        "            with open(img_name, \"rb\") as f:\n",
        "                img = f.read()\n",
        "                data = {\"image\": img}\n",
        "\n",
        "            batch = transform(data, detOPS)\n",
        "            images = np.expand_dims(batch[0], axis=0)\n",
        "            shape_list = np.expand_dims(batch[1], axis=0)\n",
        "            images = paddle.to_tensor(images)\n",
        "\n",
        "            # forward & post process\n",
        "            preds = detModel(images)\n",
        "            det_res = detPost(preds, shape_list)\n",
        "\n",
        "            # parser boxes if post_result is dict\n",
        "            if isinstance(det_res, dict):\n",
        "                for k in det_res.keys():\n",
        "                    boxes = det_res[k][0][\"points\"]\n",
        "            else:\n",
        "                boxes = det_res[0][\"points\"]\n",
        "\n",
        "            # Crop to patches\n",
        "            ori_img = cv2.imread(img_name)\n",
        "            h, w, c = ori_img.shape\n",
        "            if not os.path.exists(tmp_folder_path):\n",
        "                os.mkdir(tmp_folder_path)\n",
        "\n",
        "            for i, box in enumerate(boxes):\n",
        "                pt = box.tolist()\n",
        "                try:\n",
        "                    xs = [x[0] for x in pt]\n",
        "                    xs = np.clip(np.array(xs), a_min=0, a_max=w).tolist()\n",
        "                    ys = [x[1] for x in pt]\n",
        "                    ys = np.clip(np.array(ys), a_min=0, a_max=h).tolist()\n",
        "                    minx = min(xs)\n",
        "                    miny = min(ys)\n",
        "                    maxx = max(xs)\n",
        "                    maxy = max(ys)\n",
        "\n",
        "                    if (maxx - minx) <= 0 or (maxy - miny) <= 0:\n",
        "                        print(\n",
        "                            \"BBOX error occured when cropping image\"\n",
        "                            f\" {os.path.basename(img_name)} of {i}-th box\"\n",
        "                        )\n",
        "                        print(f\"Processed BBOX {minx} {miny} {maxx} {maxy}\")\n",
        "                        print(f\"Ori BBOX {pt}\")\n",
        "                        continue\n",
        "\n",
        "                    crop = ori_img[miny:maxy, minx:maxx]\n",
        "                    tmp_img_name = os.path.join(\n",
        "                        \"{}/{}_{}.jpg\".format(\n",
        "                            tmp_folder_path,\n",
        "                            img_name.split(\"/\")[-1].split(\".\")[0],\n",
        "                            str(i),\n",
        "                        )\n",
        "                    )\n",
        "                    cv2.imwrite(tmp_img_name, crop)\n",
        "                except Exception as e:\n",
        "                    print(\n",
        "                        f\"Error {e} occured when cropping image\"\n",
        "                        f\" {os.path.basename(img_name)} of {i}-th box\"\n",
        "                    )\n",
        "                    continue\n",
        "\n",
        "            boxes_len = len(boxes)\n",
        "            tmp_folder_len = len(os.listdir(tmp_folder_path))\n",
        "            if boxes_len == 0 or tmp_folder_len == 0:\n",
        "                print(\n",
        "                    f\"No output for {os.path.basename(img_name)}, bbox_len:\"\n",
        "                    f\" {boxes_len}, tmp_len: {tmp_folder_len}\"\n",
        "                )\n",
        "                shutil.rmtree(tmp_folder_path)\n",
        "                continue\n",
        "\n",
        "            if boxes_len != tmp_folder_len:\n",
        "                print(\n",
        "                    f\"mismatch bbox_len {boxes_len} and tmp_len {tmp_folder_len} for\"\n",
        "                    f\" image {os.path.basename(img_name)}\"\n",
        "                )\n",
        "                shutil.rmtree(tmp_folder_path)\n",
        "                continue\n",
        "\n",
        "            # ------------------------- Stage II Recognition ------------------------------\n",
        "            for file in get_image_file_list(tmp_folder_path):\n",
        "                with open(file, \"rb\") as f:\n",
        "                    img = f.read()\n",
        "                    data = {\"image\": img}\n",
        "                batch = transform(data, recOPS)\n",
        "                images = np.expand_dims(batch[0], axis=0)\n",
        "                images = paddle.to_tensor(images)\n",
        "                preds = recModel(images)\n",
        "\n",
        "                rec_res = recPost(preds)\n",
        "                formatted_res = rec_res[0][0].replace(\" \", \"\")\n",
        "\n",
        "                b_id = int(file.split(\"_\")[-1].replace(\".jpg\", \"\"))\n",
        "                crt_box = boxes[b_id]\n",
        "\n",
        "                output_dict[img_id].append(\n",
        "                    {\n",
        "                        \"points\": crt_box.tolist(),\n",
        "                        \"transcription\": formatted_res,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            shutil.rmtree(tmp_folder_path)\n",
        "\n",
        "            out_f.write(f\"{img_id}\\t{json.dumps(output_dict[img_id])}\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FXw9mv5PTPUY"
      },
      "source": [
        "## Evaluated with Pre-trained Models\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qkVCWdZvPxq9"
      },
      "source": [
        "### Text Detection (Pre-trained EAST)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9WzRLbMjM1fr"
      },
      "outputs": [],
      "source": [
        "reset_dygraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRhS2KSZcheZ",
        "outputId": "47d3d12c-10e0-4273-97cc-682f28c980b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:49:59] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:31<00:00,  1.58s/it]\n"
          ]
        }
      ],
      "source": [
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_output\"\n",
        ")\n",
        "vis_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_output/vis\"\n",
        ")\n",
        "det_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
        "out_txt_name = \"east_output\"\n",
        "\n",
        "det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpDrLo97nYaE",
        "outputId": "057f615b-3be7-4203-8ad5-d0b80c4a67b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.06, Recall: 0.25, HMean: 0.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the HMean for them\n",
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": False,\n",
        "}\n",
        "\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_output/east_output.txt\"\n",
        ")\n",
        "resDict = det_eval(gt_path, det_path, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gwzLm-WC0pMi"
      },
      "source": [
        "### Text Recognition (Pre-trained CRNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBIKUCHn0uOe",
        "outputId": "929ee3ac-1cc4-4abe-ab97-ff57dc675772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:50:36] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n",
            "[2023/05/15 02:50:36] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n",
            "[2023/05/15 02:50:36] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:06<00:00,  3.30it/s]\n"
          ]
        }
      ],
      "source": [
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/crnn_output\"\n",
        ")\n",
        "reg_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n",
        "out_txt_name = \"crnn_output\"\n",
        "\n",
        "rec_ppocr(out_path, reg_yml, img_path, out_txt_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRYFc5Bi5cMP",
        "outputId": "28466886-a266-43f3-8843-402fa704708a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Correctly Recognized Words: 0\n",
            "Total Correctly Recognized Words (Case Insensitive): 0\n",
            "Accuracy: 0.0 %\n",
            "Accuracy (Case Insensitive): 0.0 %\n",
            "Total Edit Distance: 319\n",
            "Total Edit Distance (Case Insensitive): 312\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the Accuracy for them\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/crnn_output/crnn_output.txt\"\n",
        ")\n",
        "gt, pred = data_prep_rec_eval(gt_path, det_path)\n",
        "total_crw, total_crw_ci = total_accuracy(gt, pred)\n",
        "total_edit, total_edit_ci = total_edit_distance(gt, pred)\n",
        "\n",
        "print(f\"Total Correctly Recognized Words: {total_crw}\")\n",
        "print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n",
        "print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n",
        "print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n",
        "print(f\"Total Edit Distance: {total_edit}\")\n",
        "print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8xtpP0rz-_CO"
      },
      "source": [
        "### Text Spotting (Pre-trained EAST + CRNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "67LlRxZSM1ft"
      },
      "outputs": [],
      "source": [
        "reset_dygraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEkm-Rkh--DK",
        "outputId": "f674cc99-b61b-40a7-e069-4f767b939e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:50:44] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\n",
            "[2023/05/15 02:50:44] ppocr WARNING: The shape of model params head.fc.bias [64] not matched with loaded params head.fc.bias [37] !\n",
            "[2023/05/15 02:50:44] ppocr WARNING: The shape of model params head.fc.weight [192, 64] not matched with loaded params head.fc.weight [192, 37] !\n",
            "[2023/05/15 02:50:44] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:22<00:00,  1.11s/it]\n"
          ]
        }
      ],
      "source": [
        "tmp_folder_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_crnn_output/tmp\"\n",
        ")\n",
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_crnn_output\"\n",
        ")\n",
        "det_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_east/det_mv3_east.yml\"\n",
        ")\n",
        "reg_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
        "out_txt_name = \"east_crnn_output\"\n",
        "\n",
        "spot_ppocr(tmp_folder_path, out_path, det_yml, reg_yml, img_path, out_txt_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUrvo2rT915O",
        "outputId": "24b4f18e-cbac-4e1a-b0b9-32b7f0e287f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.0, Recall: 0.0, HMean: 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the HMean for them\n",
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/pretrained_results/east_crnn_output/east_crnn_output.txt\"\n",
        ")\n",
        "resDict = det_eval(gt_path, det_path, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BW3XTzN8TPUb"
      },
      "source": [
        "## Evaluate with Fine-tuned Models\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7F1pG3iTPUb"
      },
      "source": [
        "Fine-tuning EAST\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7r65AU7aFp-B"
      },
      "outputs": [],
      "source": [
        "# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n",
        "# Please set Global.use_gpu=True if you are running on a machine with GPU\n",
        "# Fine-tuning for 100 epochs took 4 mins 29 secs on V100\n",
        "\n",
        "# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\" \\\n",
        "# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_east/det_mv3_east_v2.0_train/best_accuracy\" Global.use_gpu=False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "xUlpKV9-y-lM"
      },
      "source": [
        "Fine-tuning CRNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AUqMuLg8I17_"
      },
      "outputs": [],
      "source": [
        "# Since we cant use GPU for ppocr here, so I set Global.use_gpu=False\n",
        "# Please set Global.use_gpu=True if you are running on a machine with GPU\n",
        "# Fine-tuning for 200 epochs took 5 mins 47 secs on V100\n",
        "\n",
        "# !python tools/train.py -c \"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\" \\\n",
        "# -o Global.pretrained_model=\"/content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/ppocr_crnn/rec_mv3_none_bilstm_ctc_v2.0_train/best_accuracy\" Global.use_gpu=False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2jhnx3NmzDwX"
      },
      "source": [
        "### Text Detection (Fine-tuned EAST)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "y_dxujK16_sZ"
      },
      "outputs": [],
      "source": [
        "reset_dygraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezu45JVlzLp6",
        "outputId": "65237546-05c6-45cc-bbae-bf4d41cf3680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:51:08] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:18<00:00,  1.07it/s]\n"
          ]
        }
      ],
      "source": [
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_output\"\n",
        ")\n",
        "vis_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_output/vis\"\n",
        ")\n",
        "det_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
        "out_txt_name = \"east_output\"\n",
        "ft_model_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",
        ")\n",
        "\n",
        "det_ppocr(out_path, vis_path, det_yml, img_path, out_txt_name, ft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXH2SiLu2Dq7",
        "outputId": "dd8729c8-fd0c-44f9-990d-a0bee5068daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.91, Recall: 1.0, HMean: 0.95\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the HMean for them\n",
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": False,\n",
        "}\n",
        "\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_output/east_output.txt\"\n",
        ")\n",
        "resDict = det_eval(gt_path, det_path, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-zVcdOzHzHI-"
      },
      "source": [
        "### Text Recognition (Fine-tuned CRNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFFf-JGQzIbk",
        "outputId": "87a5c1fb-6b2e-48f4-d237-dfb999f21231"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:51:28] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 46.98it/s]\n"
          ]
        }
      ],
      "source": [
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/crnn_output\"\n",
        ")\n",
        "reg_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val_crop\"\n",
        "out_txt_name = \"crnn_output\"\n",
        "ft_model_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",
        ")\n",
        "\n",
        "rec_ppocr(out_path, reg_yml, img_path, out_txt_name, ft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBEByfMx2IBk",
        "outputId": "1787b335-81d2-4f7c-eabc-474ffa24cb57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Correctly Recognized Words: 16\n",
            "Total Correctly Recognized Words (Case Insensitive): 16\n",
            "Accuracy: 80.0 %\n",
            "Accuracy (Case Insensitive): 80.0 %\n",
            "Total Edit Distance: 8\n",
            "Total Edit Distance (Case Insensitive): 8\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the Accuracy for them\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val_rec.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/crnn_output/crnn_output.txt\"\n",
        ")\n",
        "gt, pred = data_prep_rec_eval(gt_path, det_path)\n",
        "total_crw, total_crw_ci = total_accuracy(gt, pred)\n",
        "total_edit, total_edit_ci = total_edit_distance(gt, pred)\n",
        "\n",
        "print(f\"Total Correctly Recognized Words: {total_crw}\")\n",
        "print(f\"Total Correctly Recognized Words (Case Insensitive): {total_crw_ci}\")\n",
        "print(f\"Accuracy: {round(total_crw/len(gt)*100, 2)} %\")\n",
        "print(f\"Accuracy (Case Insensitive): {round(total_crw_ci/len(gt)*100, 2)} %\")\n",
        "print(f\"Total Edit Distance: {total_edit}\")\n",
        "print(f\"Total Edit Distance (Case Insensitive): {total_edit_ci}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ttAzKBbBEh2V"
      },
      "source": [
        "### Text Spotting (Fine-tuned + CRNN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vTau0TqGCkGT"
      },
      "outputs": [],
      "source": [
        "reset_dygraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNfIEJ5yErX8",
        "outputId": "1ee62960-55e6-4008-bb50-565810fa85ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023/05/15 02:51:29] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\n",
            "[2023/05/15 02:51:29] ppocr INFO: load pretrain successful from /content/drive/My Drive/Colab Notebooks/Chapter 4/License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:22<00:00,  1.14s/it]\n"
          ]
        }
      ],
      "source": [
        "tmp_folder_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_crnn_output/tmp\"\n",
        ")\n",
        "out_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_crnn_output\"\n",
        ")\n",
        "det_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_east/ft_det_mv3_east.yml\"\n",
        ")\n",
        "reg_yml = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/ppocr_crnn/ft_rec_mv3_none_bilstm_ctc.yml\"\n",
        ")\n",
        "img_path = \"/content/drive/My Drive/CCPD2019/val\"\n",
        "out_txt_name = \"east_crnn_output\"\n",
        "det_ft_model_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/fine_tuned_ccpd/east/best_accuracy\"\n",
        ")\n",
        "rec_ft_model_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/fine_tuned_ccpd/crnn/best_accuracy\"\n",
        ")\n",
        "\n",
        "spot_ppocr(\n",
        "    tmp_folder_path,\n",
        "    out_path,\n",
        "    det_yml,\n",
        "    reg_yml,\n",
        "    img_path,\n",
        "    out_txt_name,\n",
        "    det_ft_model_path,\n",
        "    rec_ft_model_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqXZOeC7Eyko",
        "outputId": "5cc71191-66c2-47f0-e82e-a48bd45e4eee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.45, Recall: 0.5, HMean: 0.48\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's evaluate the HMean for them\n",
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gt_path = \"/content/drive/My Drive/CCPD2019/val.txt\"\n",
        "det_path = (\n",
        "    \"/content/drive/My Drive/Colab Notebooks/Chapter 4/\"\n",
        "    \"License_Plate_Recognition/finetuned_results/east_crnn_output/east_crnn_output.txt\"\n",
        ")\n",
        "resDict = det_eval(gt_path, det_path, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
