{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yyVUdGisrriu"
      },
      "source": [
        "# 2. HMean Calculation for Text Detection & Spotting Tasks\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPdJBb15rriw"
      },
      "source": [
        "In this notebook, we will learn how the evaluation metrics (IoU, HMean, Precision, and Recall) for text detection and spotting are computed. We will first install and import the necessary libraries; then go through the code for the evaluation methods. Lastly, we will examine examples of how the evaluation is carried out and obtain insights into each metric's measures.\n",
        "\n",
        "**Table of Contents**\n",
        "\n",
        "1. [Installation](#installation)\n",
        "2. [Evaluation & Helper Methods](#evaluation--helper-methods)\n",
        "3. [Evaluation Examples](#evaluation-examples)\n",
        "\n",
        "Get your seatbelt on and let's get started! 🔥⭐\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3ejuZ5qFrrix"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PROYQHinRS_Z",
        "outputId": "72cd1c20-3b1e-4bd3-cfb8-9ce64e16c9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Polygon3\n",
            "  Downloading Polygon3-3.0.9.1.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: Polygon3\n",
            "  Building wheel for Polygon3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Polygon3: filename=Polygon3-3.0.9.1-cp310-cp310-linux_x86_64.whl size=119431 sha256=e0dd7d2786ddf169b8db7b389229a3ad34206ac4d04a6bfc6f6485d9decf5532\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/b7/f6/b4e24f56a1cc9856dca98cc2fdc3915d7649b39b62f3dbca9e\n",
            "Successfully built Polygon3\n",
            "Installing collected packages: Polygon3\n",
            "Successfully installed Polygon3-3.0.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install Polygon3\n",
        "!pip install Pillow"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o-SHDqbQrriz"
      },
      "source": [
        "## Evaluation & Helper Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o_VLfCX0RPfK"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import Polygon as plg\n",
        "from PIL import Image, ImageDraw\n",
        "from typing import Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aUZL1wBXy5kN"
      },
      "outputs": [],
      "source": [
        "def evaluation(gt_dict: Dict[str, List], det_dict: Dict[str, List], eval_config: Dict):\n",
        "    \"\"\"Evaluate the prediction results in terms of precision, recall and HMean.\n",
        "    The matching between ground-truth and predicted bounding box is based on the order in the list.\n",
        "    In other words, a ground-truth box will match with the first predicted bounding box with IoU > IOU_CONSTRAINT.\n",
        "\n",
        "    Args:\n",
        "        gt_dict (Dict[str, list]): A dictionary with image id as the key and a list of its ground-truth\n",
        "         bounding boxes as the value.\n",
        "         e.g.: gt_dict = {'img1': [[20, 20, 120, 60, \"Hello\"],\n",
        "                                 [200, 100, 300, 140, \"World\"],\n",
        "                                 [80, 180, 180, 220, \"###\"]]}\n",
        "        det_dict (Dict[str, list]): A dictionary with image id as the key and a list of its predicted\n",
        "         bounding boxes as the value.\n",
        "         e.g.: det_dict = {'img1': [[105, 40, 205, 80, \"Hello\"],\n",
        "                                  [210, 105, 310, 145, \"World\"],\n",
        "                                  [70, 170, 170, 210, \"Random\"]]}\n",
        "        eval_config (dict): A dictionary storing the evaluation configuration.\n",
        "         e.g.: eval_config = {\"IOU_CONSTRAINT\": 0.5,\n",
        "                            \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "                            \"WORD_SPOTTING\": True,\n",
        "                        }\n",
        "    Returns:\n",
        "        resDict (Dict): A dict storing overall and per-sample evaluation result\n",
        "    \"\"\"\n",
        "\n",
        "    def rectangle_to_polygon(rect):\n",
        "        resBoxes = np.empty([1, 8], dtype=\"int32\")\n",
        "        resBoxes[0, 0] = int(rect.xmin)\n",
        "        resBoxes[0, 4] = int(rect.ymax)\n",
        "        resBoxes[0, 1] = int(rect.xmin)\n",
        "        resBoxes[0, 5] = int(rect.ymin)\n",
        "        resBoxes[0, 2] = int(rect.xmax)\n",
        "        resBoxes[0, 6] = int(rect.ymin)\n",
        "        resBoxes[0, 3] = int(rect.xmax)\n",
        "        resBoxes[0, 7] = int(rect.ymax)\n",
        "\n",
        "        pointMat = resBoxes[0].reshape([2, 4]).T\n",
        "\n",
        "        return plg.Polygon(pointMat)\n",
        "\n",
        "    def get_union(pD, pG):\n",
        "        areaA = pD.area()\n",
        "        areaB = pG.area()\n",
        "        return areaA + areaB - get_intersection(pD, pG)\n",
        "\n",
        "    def get_intersection_over_union(pD, pG):\n",
        "        try:\n",
        "            return get_intersection(pD, pG) / get_union(pD, pG)\n",
        "        except:\n",
        "            return 0\n",
        "\n",
        "    def get_intersection(pD, pG):\n",
        "        pInt = pD & pG\n",
        "        if len(pInt) == 0:\n",
        "            return 0\n",
        "        return pInt.area()\n",
        "\n",
        "    perSampleMetrics = {}\n",
        "    matchedSum = 0\n",
        "    Rectangle = namedtuple(\"Rectangle\", \"xmin ymin xmax ymax\")\n",
        "    numGlobalCareGt = 0\n",
        "    numGlobalCareDet = 0\n",
        "\n",
        "    # loop through each image id\n",
        "    for gt_key, gt_val in gt_dict.items():\n",
        "        recall = 0\n",
        "        precision = 0\n",
        "        hmean = 0\n",
        "        detMatched = 0\n",
        "        iouMat = np.empty([1, 1])\n",
        "\n",
        "        gtPols = []\n",
        "        detPols = []\n",
        "        gtPolPoints = []\n",
        "        detPolPoints = []\n",
        "        # Array of Ground Truth Polygons' keys marked as don't Care\n",
        "        gtDontCarePolsNum = []\n",
        "        # Array of Detected Polygons' matched with a don't Care GT\n",
        "        detDontCarePolsNum = []\n",
        "        pairs = []\n",
        "        detMatchedNums = []\n",
        "        if eval_config[\"WORD_SPOTTING\"]:\n",
        "            gtTrans = []\n",
        "            detTrans = []\n",
        "\n",
        "        evaluationLog = \"\"\n",
        "\n",
        "        # loop through all bounding boxes in an image\n",
        "        for n in range(len(gt_val)):\n",
        "            list_entry = gt_val[n]\n",
        "\n",
        "            if eval_config[\"WORD_SPOTTING\"]:\n",
        "                # append ground-truth transcript\n",
        "                gtTrans.append(list_entry[-1])\n",
        "\n",
        "            points = list_entry[:4]\n",
        "            transcription = list_entry[4]\n",
        "            gtRect = Rectangle(*points)\n",
        "            gtPol = rectangle_to_polygon(gtRect)\n",
        "\n",
        "            gtPols.append(gtPol)\n",
        "            gtPolPoints.append(points)\n",
        "            if transcription == \"###\":\n",
        "                gtDontCarePolsNum.append(len(gtPols) - 1)\n",
        "\n",
        "        evaluationLog += (\n",
        "            \"GT polygons: \"\n",
        "            + str(len(gtPols))\n",
        "            + (\n",
        "                \" (\" + str(len(gtDontCarePolsNum)) + \" don't care)\\n\"\n",
        "                if len(gtDontCarePolsNum) > 0\n",
        "                else \"\\n\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # if there's bounding box in prediction\n",
        "        if gt_key in det_dict.keys():\n",
        "            det_val = det_dict[gt_key]\n",
        "            for n in range(len(det_val)):\n",
        "                points = det_val[n][:4]\n",
        "                if eval_config[\"WORD_SPOTTING\"]:\n",
        "                    detTrans.append(det_val[n][-1])\n",
        "\n",
        "                detRect = Rectangle(*points)\n",
        "                detPol = rectangle_to_polygon(detRect)\n",
        "\n",
        "                detPols.append(detPol)\n",
        "                detPolPoints.append(points)\n",
        "                # if there's 'dont care' boxes in ground-truth\n",
        "                if len(gtDontCarePolsNum) > 0:\n",
        "                    # we only care about the predicted bounding box\n",
        "                    for dontCarePol in gtDontCarePolsNum:\n",
        "                        dontCarePol = gtPols[dontCarePol]\n",
        "                        intersected_area = get_intersection(dontCarePol, detPol)\n",
        "                        pdDimensions = detPol.area()\n",
        "                        precision = (\n",
        "                            0 if pdDimensions == 0 else intersected_area / pdDimensions\n",
        "                        )\n",
        "                        if precision > eval_config[\"AREA_PRECISION_CONSTRAINT\"]:\n",
        "                            detDontCarePolsNum.append(len(detPols) - 1)\n",
        "                            break\n",
        "\n",
        "            evaluationLog += (\n",
        "                \"DET polygons: \"\n",
        "                + str(len(detPols))\n",
        "                + (\n",
        "                    \" (\" + str(len(detDontCarePolsNum)) + \" don't care)\\n\"\n",
        "                    if len(detDontCarePolsNum) > 0\n",
        "                    else \"\\n\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if len(gtPols) > 0 and len(detPols) > 0:\n",
        "                # Calculate IoU and precision matrixs\n",
        "                outputShape = [len(gtPols), len(detPols)]\n",
        "                iouMat = np.empty(outputShape)\n",
        "                gtRectMat = np.zeros(len(gtPols), np.int8)\n",
        "                detRectMat = np.zeros(len(detPols), np.int8)\n",
        "                for gtNum in range(len(gtPols)):\n",
        "                    for detNum in range(len(detPols)):\n",
        "                        pG = gtPols[gtNum]\n",
        "                        pD = detPols[detNum]\n",
        "                        iouMat[gtNum, detNum] = get_intersection_over_union(pD, pG)\n",
        "\n",
        "                for gtNum in range(len(gtPols)):\n",
        "                    for detNum in range(len(detPols)):\n",
        "                        if (\n",
        "                            gtRectMat[gtNum] == 0\n",
        "                            and detRectMat[detNum] == 0\n",
        "                            and gtNum not in gtDontCarePolsNum\n",
        "                            and detNum not in detDontCarePolsNum\n",
        "                        ):\n",
        "                            if iouMat[gtNum, detNum] > eval_config[\"IOU_CONSTRAINT\"]:\n",
        "                                gtRectMat[gtNum] = 1\n",
        "                                detRectMat[detNum] = 1\n",
        "                                if eval_config[\"WORD_SPOTTING\"]:\n",
        "                                    correct = (\n",
        "                                        gtTrans[gtNum].upper()\n",
        "                                        == detTrans[detNum].upper()\n",
        "                                    )\n",
        "                                    if correct:\n",
        "                                        detMatched += 1\n",
        "                                        pairs.append(\n",
        "                                            {\n",
        "                                                \"gt\": gtNum,\n",
        "                                                \"det\": detNum,\n",
        "                                                \"correct\": correct,\n",
        "                                            }\n",
        "                                        )\n",
        "                                        detMatchedNums.append(detNum)\n",
        "                                        evaluationLog += (\n",
        "                                            \"Match GT #\"\n",
        "                                            + str(gtNum)\n",
        "                                            + \" with Det #\"\n",
        "                                            + str(detNum)\n",
        "                                            + \" trans. correct: \"\n",
        "                                            + str(correct)\n",
        "                                            + \"\\n\"\n",
        "                                        )\n",
        "                                else:\n",
        "                                    detMatched += 1\n",
        "                                    pairs.append({\"gt\": gtNum, \"det\": detNum})\n",
        "                                    detMatchedNums.append(detNum)\n",
        "                                    evaluationLog += (\n",
        "                                        \"Match GT #\"\n",
        "                                        + str(gtNum)\n",
        "                                        + \" with Det #\"\n",
        "                                        + str(detNum)\n",
        "                                        + \"\\n\"\n",
        "                                    )\n",
        "\n",
        "            numGtCare = len(gtPols) - len(gtDontCarePolsNum)\n",
        "            # print(len(gtPols), len(gtDontCarePolsNum))\n",
        "            numDetCare = len(detPols) - len(detDontCarePolsNum)\n",
        "            # print(len(detPols), len(detDontCarePolsNum))\n",
        "            if numGtCare == 0:\n",
        "                recall = float(1)\n",
        "                precision = float(0) if numDetCare > 0 else float(1)\n",
        "            else:\n",
        "                recall = float(detMatched) / numGtCare\n",
        "                precision = 0 if numDetCare == 0 else float(detMatched) / numDetCare\n",
        "\n",
        "            hmean = (\n",
        "                0\n",
        "                if (precision + recall) == 0\n",
        "                else 2.0 * precision * recall / (precision + recall)\n",
        "            )\n",
        "\n",
        "            matchedSum += detMatched\n",
        "            numGlobalCareGt += numGtCare\n",
        "            numGlobalCareDet += numDetCare\n",
        "\n",
        "            perSampleMetrics[gt_key] = {\n",
        "                \"precision\": precision,\n",
        "                \"recall\": recall,\n",
        "                \"hmean\": hmean,\n",
        "                \"pairs\": pairs,\n",
        "                \"iouMat\": [] if len(detPols) > 100 else iouMat.tolist(),\n",
        "                \"gtPolPoints\": gtPolPoints,\n",
        "                \"detPolPoints\": detPolPoints,\n",
        "                \"gtDontCare\": gtDontCarePolsNum,\n",
        "                \"detDontCare\": detDontCarePolsNum,\n",
        "                \"eval_config\": eval_config,\n",
        "                \"evaluationLog\": evaluationLog,\n",
        "            }\n",
        "\n",
        "            if eval_config[\"WORD_SPOTTING\"]:\n",
        "                perSampleMetrics[gt_key][\"gtTrans\"] = gtTrans\n",
        "                perSampleMetrics[gt_key][\"detTrans\"] = detTrans\n",
        "\n",
        "    methodRecall = 0 if numGlobalCareGt == 0 else float(matchedSum) / numGlobalCareGt\n",
        "    methodPrecision = (\n",
        "        0 if numGlobalCareDet == 0 else float(matchedSum) / numGlobalCareDet\n",
        "    )\n",
        "    methodHmean = (\n",
        "        0\n",
        "        if methodRecall + methodPrecision == 0\n",
        "        else 2 * methodRecall * methodPrecision / (methodRecall + methodPrecision)\n",
        "    )\n",
        "\n",
        "    methodMetrics = {\n",
        "        \"precision\": methodPrecision,\n",
        "        \"recall\": methodRecall,\n",
        "        \"hmean\": methodHmean,\n",
        "    }\n",
        "\n",
        "    resDict = {\n",
        "        \"calculated\": True,\n",
        "        \"Message\": \"\",\n",
        "        \"method\": methodMetrics,\n",
        "        \"per_sample\": perSampleMetrics,\n",
        "    }\n",
        "\n",
        "    return resDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LDbUKpaFXXLd"
      },
      "outputs": [],
      "source": [
        "def draw_img(gtPointsList: List, detPointsList: List, image_size: int):\n",
        "    new_img = Image.new(\"RGB\", (image_size, image_size), \"white\")\n",
        "\n",
        "    draw = ImageDraw.Draw(new_img)\n",
        "    text_offset = 2\n",
        "\n",
        "    for i in range(len(gtPointsList)):\n",
        "        if gtPointsList[i][4] == \"###\":\n",
        "            outline = \"blue\"\n",
        "        else:\n",
        "            outline = \"green\"\n",
        "        draw.rectangle(\n",
        "            (\n",
        "                (gtPointsList[i][0], gtPointsList[i][1]),\n",
        "                (gtPointsList[i][2], gtPointsList[i][3]),\n",
        "            ),\n",
        "            outline=outline,\n",
        "            width=3,\n",
        "        )\n",
        "\n",
        "        # Add Text to an image\n",
        "        draw.text(\n",
        "            (gtPointsList[i][0] + text_offset * 2, gtPointsList[i][1] + text_offset),\n",
        "            gtPointsList[i][4],\n",
        "            fill=outline,\n",
        "        )\n",
        "\n",
        "    for i in range(len(detPointsList)):\n",
        "        draw.rectangle(\n",
        "            (\n",
        "                (detPointsList[i][0], detPointsList[i][1]),\n",
        "                (detPointsList[i][2], detPointsList[i][3]),\n",
        "            ),\n",
        "            outline=\"red\",\n",
        "            width=3,\n",
        "        )\n",
        "        draw.text(\n",
        "            (detPointsList[i][0] + text_offset * 2, detPointsList[i][1] + text_offset),\n",
        "            detPointsList[i][4],\n",
        "            fill=\"red\",\n",
        "        )\n",
        "\n",
        "    return new_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cV9XilTXDmY9"
      },
      "outputs": [],
      "source": [
        "def format_dict(resDict: Dict[str, List], img_id: str):\n",
        "    \"\"\"Extract per-sample metric from the resDict based on img_id\n",
        "\n",
        "    Args:\n",
        "        resDict (Dict[str, List]): Result dictionary from `evaluation()`\n",
        "        img_id (str): Image to be investigated\n",
        "\n",
        "    Returns:\n",
        "        matched_str (str): Matched GT bounding box index and predicted bounding box index and the respective IoU\n",
        "        ignore_str (str): Ignored GT bounding box index and predicted bounding box index and the respective IoU\n",
        "        unmatched_str (str): Unmatch GT bounding box index and predicted bounding box index and the respective IoU\n",
        "    \"\"\"\n",
        "    matched_str = \"\"\n",
        "    ignore_str = \"\"\n",
        "    unmatched_str = \"\"\n",
        "    matched_pairs = resDict[\"per_sample\"][img_id][\"pairs\"]\n",
        "\n",
        "    discovered_gts = []\n",
        "    discovered_dets = []\n",
        "    undiscovered_gts = []\n",
        "    undiscovered_dets = []\n",
        "\n",
        "    for pair in matched_pairs:\n",
        "        gt_id = pair[\"gt\"]\n",
        "        det_id = pair[\"det\"]\n",
        "        matched_str += (\n",
        "            f\"MATCHED GT {gt_id} and MATCHED PRED {det_id} IoU:\"\n",
        "            f\" {round(resDict['per_sample'][img_id]['iouMat'][gt_id][det_id], 2)}\\n\"\n",
        "        )\n",
        "        discovered_gts.append(gt_id)\n",
        "        discovered_dets.append(det_id)\n",
        "\n",
        "    for gt_id, det_id in zip(\n",
        "        resDict[\"per_sample\"][img_id][\"gtDontCare\"],\n",
        "        resDict[\"per_sample\"][img_id][\"detDontCare\"],\n",
        "    ):\n",
        "        ignore_str += (\n",
        "            f\"IGNORED GT {gt_id} and IGNORED PRED {det_id} IoU:\"\n",
        "            f\" {round(resDict['per_sample'][img_id]['iouMat'][gt_id][det_id], 2)}\\n\"\n",
        "        )\n",
        "        discovered_gts.append(gt_id)\n",
        "        discovered_dets.append(det_id)\n",
        "\n",
        "    for gt_id in range(len(resDict[\"per_sample\"][img_id][\"gtPolPoints\"])):\n",
        "        if gt_id not in discovered_gts:\n",
        "            undiscovered_gts.append(gt_id)\n",
        "\n",
        "    for det_id in range(len(resDict[\"per_sample\"][img_id][\"detPolPoints\"])):\n",
        "        if det_id not in discovered_dets:\n",
        "            undiscovered_dets.append(det_id)\n",
        "\n",
        "    for gt_id in undiscovered_gts:\n",
        "        for det_id in undiscovered_dets:\n",
        "            unmatched_str += (\n",
        "                f\"UNMATCHED GT {gt_id} and UNMATCHED PRED {det_id} IoU:\"\n",
        "                f\" {round(resDict['per_sample'][img_id]['iouMat'][gt_id][det_id], 2)}\\n\"\n",
        "            )\n",
        "\n",
        "    return matched_str, ignore_str, unmatched_str"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a8gYdOlWrri1"
      },
      "source": [
        "## Evaluation Examples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CIAgM2CDrri2"
      },
      "source": [
        "### Example 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "jJq49S9cTAnk",
        "outputId": "8f8e6a12-db62-4827-cde6-113e3c1a09df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=350x350 at 0x7FF232A9F550>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.5, Recall: 0.5, HMean: 0.5\n",
            "\n",
            "---Per Sample Metric---\n",
            "---Matched---\n",
            "MATCHED GT 1 and MATCHED PRED 1 IoU: 0.65\n",
            "\n",
            "---Ignored---\n",
            "IGNORED GT 2 and IGNORED PRED 2 IoU: 0.51\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 0 and UNMATCHED PRED 0 IoU: 0.04\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gtPointsList = [\n",
        "    [20, 20, 120, 60, \"Hello\"],\n",
        "    [200, 100, 300, 140, \"World\"],\n",
        "    [80, 180, 180, 220, \"###\"],\n",
        "]\n",
        "detPointsList = [\n",
        "    [105, 40, 205, 80, \"Hello\"],\n",
        "    [210, 105, 310, 145, \"World\"],\n",
        "    [70, 170, 170, 210, \"Random\"],\n",
        "]\n",
        "\n",
        "img_id = \"img_1\"\n",
        "gt_dict = {img_id: gtPointsList}\n",
        "det_dict = {img_id: detPointsList}\n",
        "\n",
        "demo_img = draw_img(gtPointsList, detPointsList, 350)\n",
        "demo_img.show()\n",
        "resDict = evaluation(gt_dict, det_dict, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")\n",
        "\n",
        "matched_str, ignore_str, unmatched_str = format_dict(resDict, img_id)\n",
        "\n",
        "print(\"---Per Sample Metric---\")\n",
        "\n",
        "if matched_str != \"\":\n",
        "    print(\"---Matched---\")\n",
        "    print(matched_str)\n",
        "\n",
        "if ignore_str != \"\":\n",
        "    print(\"---Ignored---\")\n",
        "    print(ignore_str)\n",
        "\n",
        "if unmatched_str != \"\":\n",
        "    print(\"---Unmatched---\")\n",
        "    print(unmatched_str)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ5DX_Mqrri2"
      },
      "source": [
        "### Example 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "5EeGdzUcZSEs",
        "outputId": "3a20cd12-add1-463a-ea23-8ea271e21719"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=350x350 at 0x7FF21AA7AD40>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.67, Recall: 0.67, HMean: 0.67\n",
            "\n",
            "---Per Sample Metric---\n",
            "---Matched---\n",
            "MATCHED GT 0 and MATCHED PRED 0 IoU: 0.66\n",
            "MATCHED GT 2 and MATCHED PRED 2 IoU: 0.55\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 1 and UNMATCHED PRED 1 IoU: 0.11\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gtPointsList = [\n",
        "    [20, 40, 120, 80, \"Hello\"],\n",
        "    [200, 80, 280, 120, \"World\"],\n",
        "    [70, 160, 170, 200, \"12345\"],\n",
        "]\n",
        "detPointsList = [\n",
        "    [25, 35, 135, 75, \"Hello\"],\n",
        "    [150, 90, 220, 130, \"World\"],\n",
        "    [90, 158, 150, 198, \"12345\"],\n",
        "]\n",
        "\n",
        "img_id = \"img_2\"\n",
        "gt_dict = {img_id: gtPointsList}\n",
        "det_dict = {img_id: detPointsList}\n",
        "\n",
        "demo_img = draw_img(gtPointsList, detPointsList, 350)\n",
        "demo_img.show()\n",
        "resDict = evaluation(gt_dict, det_dict, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")\n",
        "\n",
        "matched_str, ignore_str, unmatched_str = format_dict(resDict, img_id)\n",
        "\n",
        "print(\"---Per Sample Metric---\")\n",
        "\n",
        "if matched_str != \"\":\n",
        "    print(\"---Matched---\")\n",
        "    print(matched_str)\n",
        "\n",
        "if ignore_str != \"\":\n",
        "    print(\"---Ignored---\")\n",
        "    print(ignore_str)\n",
        "\n",
        "if unmatched_str != \"\":\n",
        "    print(\"---Unmatched---\")\n",
        "    print(unmatched_str)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "N-hudq3hrri3"
      },
      "source": [
        "### Example 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "4N5ohioCgPG-",
        "outputId": "7089de6b-c313-429b-e9cd-b2dd9e09c909"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=350x350 at 0x7FF2338B8670>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.5, Recall: 0.33, HMean: 0.4\n",
            "\n",
            "---Per Sample Metric---\n",
            "---Matched---\n",
            "MATCHED GT 2 and MATCHED PRED 1 IoU: 0.55\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 0 and UNMATCHED PRED 0 IoU: 0.3\n",
            "UNMATCHED GT 1 and UNMATCHED PRED 0 IoU: 0.31\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gtPointsList = [\n",
        "    [20, 20, 120, 60, \"Hello\"],\n",
        "    [140, 30, 240, 70, \"World\"],\n",
        "    [70, 100, 170, 140, \"12345\"],\n",
        "]\n",
        "detPointsList = [[22, 15, 240, 75, \"Hello\"], [90, 98, 150, 138, \"12345\"]]\n",
        "\n",
        "img_id = \"img_3\"\n",
        "gt_dict = {img_id: gtPointsList}\n",
        "det_dict = {img_id: detPointsList}\n",
        "\n",
        "demo_img = draw_img(gtPointsList, detPointsList, 350)\n",
        "demo_img.show()\n",
        "resDict = evaluation(gt_dict, det_dict, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")\n",
        "\n",
        "matched_str, ignore_str, unmatched_str = format_dict(resDict, img_id)\n",
        "\n",
        "print(\"---Per Sample Metric---\")\n",
        "\n",
        "if matched_str != \"\":\n",
        "    print(\"---Matched---\")\n",
        "    print(matched_str)\n",
        "\n",
        "if ignore_str != \"\":\n",
        "    print(\"---Ignored---\")\n",
        "    print(ignore_str)\n",
        "\n",
        "if unmatched_str != \"\":\n",
        "    print(\"---Unmatched---\")\n",
        "    print(unmatched_str)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jW-jUA2Srri4"
      },
      "source": [
        "### Example 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BdSotxVvUFg",
        "outputId": "d4687b59-9c9b-4b84-e50d-7ca11dc3257a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Overall Metric---\n",
            "Precision: 0.43, Recall: 0.38, HMean: 0.4\n",
            "\n",
            "---Per Sample Metric of img_1---\n",
            "Precision: 0.5, Recall: 0.5, HMean: 0.5\n",
            "\n",
            "---Matched---\n",
            "MATCHED GT 1 and MATCHED PRED 1 IoU: 0.65\n",
            "\n",
            "---Ignored---\n",
            "IGNORED GT 2 and IGNORED PRED 2 IoU: 0.51\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 0 and UNMATCHED PRED 0 IoU: 0.04\n",
            "\n",
            "---Per Sample Metric of img_2---\n",
            "Precision: 0.67, Recall: 0.67, HMean: 0.67\n",
            "\n",
            "---Matched---\n",
            "MATCHED GT 0 and MATCHED PRED 0 IoU: 0.66\n",
            "MATCHED GT 2 and MATCHED PRED 2 IoU: 0.55\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 1 and UNMATCHED PRED 1 IoU: 0.11\n",
            "\n",
            "---Per Sample Metric of img_3---\n",
            "Precision: 0.0, Recall: 0.0, HMean: 0\n",
            "\n",
            "---Unmatched---\n",
            "UNMATCHED GT 0 and UNMATCHED PRED 0 IoU: 0.3\n",
            "UNMATCHED GT 0 and UNMATCHED PRED 1 IoU: 0.0\n",
            "UNMATCHED GT 1 and UNMATCHED PRED 0 IoU: 0.31\n",
            "UNMATCHED GT 1 and UNMATCHED PRED 1 IoU: 0.0\n",
            "UNMATCHED GT 2 and UNMATCHED PRED 0 IoU: 0.0\n",
            "UNMATCHED GT 2 and UNMATCHED PRED 1 IoU: 0.55\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eval_config = {\n",
        "    \"IOU_CONSTRAINT\": 0.5,\n",
        "    \"AREA_PRECISION_CONSTRAINT\": 0.5,\n",
        "    \"WORD_SPOTTING\": True,\n",
        "}\n",
        "\n",
        "gt_dict = {\n",
        "    \"img_1\": [\n",
        "        [20, 20, 120, 60, \"Hello\"],\n",
        "        [200, 100, 300, 140, \"World\"],\n",
        "        [80, 180, 180, 220, \"###\"],\n",
        "    ],\n",
        "    \"img_2\": [\n",
        "        [20, 40, 120, 80, \"Hello\"],\n",
        "        [200, 80, 280, 120, \"World\"],\n",
        "        [70, 160, 170, 200, \"12345\"],\n",
        "    ],\n",
        "    \"img_3\": [\n",
        "        [20, 20, 120, 60, \"Hello\"],\n",
        "        [140, 30, 240, 70, \"World\"],\n",
        "        [70, 100, 170, 140, \"12345\"],\n",
        "    ],\n",
        "}\n",
        "det_dict = {\n",
        "    \"img_1\": [\n",
        "        [105, 40, 205, 80, \"Hello\"],\n",
        "        [210, 105, 310, 145, \"World\"],\n",
        "        [70, 170, 170, 210, \"###\"],\n",
        "    ],\n",
        "    \"img_2\": [\n",
        "        [25, 35, 135, 75, \"Hello\"],\n",
        "        [150, 90, 220, 130, \"World\"],\n",
        "        [90, 158, 150, 198, \"12345\"],\n",
        "    ],\n",
        "    \"img_3\": [[22, 15, 240, 75, \"Hello\"], [90, 98, 150, 138, \"World\"]],\n",
        "}\n",
        "\n",
        "resDict = evaluation(gt_dict, det_dict, eval_config)\n",
        "precision, recall, hmean = (\n",
        "    resDict[\"method\"][\"precision\"],\n",
        "    resDict[\"method\"][\"recall\"],\n",
        "    resDict[\"method\"][\"hmean\"],\n",
        ")\n",
        "\n",
        "print(\"---Overall Metric---\")\n",
        "print(\n",
        "    f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "    f\" {round(hmean, 2)}\\n\"\n",
        ")\n",
        "\n",
        "for img_id in gt_dict.keys():\n",
        "    matched_str, ignore_str, unmatched_str = format_dict(resDict, img_id)\n",
        "\n",
        "    precision, recall, hmean = (\n",
        "        resDict[\"per_sample\"][img_id][\"precision\"],\n",
        "        resDict[\"per_sample\"][img_id][\"recall\"],\n",
        "        resDict[\"per_sample\"][img_id][\"hmean\"],\n",
        "    )\n",
        "\n",
        "    print(f\"---Per Sample Metric of {img_id}---\")\n",
        "    print(\n",
        "        f\"Precision: {round(precision, 2)}, Recall: {round(recall, 2)}, HMean:\"\n",
        "        f\" {round(hmean, 2)}\\n\"\n",
        "    )\n",
        "\n",
        "    if matched_str != \"\":\n",
        "        print(\"---Matched---\")\n",
        "        print(matched_str)\n",
        "\n",
        "    if ignore_str != \"\":\n",
        "        print(\"---Ignored---\")\n",
        "        print(ignore_str)\n",
        "\n",
        "    if unmatched_str != \"\":\n",
        "        print(\"---Unmatched---\")\n",
        "        print(unmatched_str)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
